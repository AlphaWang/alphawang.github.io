---
layout: post
title: "Dapper, a Large-Scale Distributed Systems Tracing Infrastructure"
date: 2019-03-24 12:04:46 +0800
comments: true
categories: [distributed system]
tags: [distributed system, tracing, dapper]
keywords: distributed system, tracing, dapper, 链路跟踪
description: Google Dapper论文的翻译
---

> 最近在研究分布式链路追踪系统，Google的DAPPER当然是必读的论文了。目前网上能搜到一些中文翻译版，然而读下来感觉翻译比较生硬；这里试着基于前人的成果重新翻译一遍这个论文，权当是个人的学习笔记，如果同时能给其他人带来好处那更好了。

原文：https://ai.google/research/pubs/pub36356

## 摘要

现代互联网服务通常都是复杂的大规模分布式系统。这些系统由多个软件模块构成，这些软件模块可能由不同的团队开发、可能使用不同的编程语言实现、可能布在横跨多个数据中心的几千台服务器上。这种环境下就急需能帮助理解系统行为、能用于分析性能问题的工具。

本文将介绍Dapper（Google生产环境下的分布式跟踪系统）的设计，并阐述它是如何满足在一个超大规模系统上达到**低损耗**（low overhead）、**应用透明**（application-level transparency）、**大范围部署**（ubiquitous deployment）这三个需求的。Dapper与其他一些跟踪系统的概念类似，尤其是Magpie和X-Trace，但是我们进行了一些特定的设计，所以它才能成功应用在我们的环境上，例如使用了采样、并限制公用库的大小。

<!--more-->

 (the use of sampling and restricting the instrumentation to a rather small number of common libraries)

这两年来，Dapper对开发和运维团队非常有用，取得了显著的成功，本文就来汇报下Dapper是如何构建、部署并应用的。最初Dapper只是一个内部使用（self-contained）的跟踪工具，后来演化成了一个监控平台并促生出许多不同的工具，有些工具甚至Dapper的设计者都未曾预期到。我们将介绍一些基于Dapper构造的分析工具，分享这些工具在Google内部使用的统计数据，展示一些使用场景的例子，并讨论我们踩过的一些坑。

## 1. 介绍

Dapper的目的是为了将复杂分布式系统的更多行为信息提供给Google开发者。这种分布式系统利用大规模的小服务器，通常对于互联网服务是一个非常经济的平台，所以很受关注。**在这种上下文中要理解系统行为的话，就需要观察横跨不同程序和不同机器的关联行为(related activities)**。

下面基于一个web搜索的例子来说明这种系统需要应对哪些挑战。前端服务器将一个web查询分发给上百台搜索服务器，每个搜索服务器在自己的index中完成搜索。同时这个web查询可能还会被发送给多个其他子系统，进行广告处理、拼写检查、查找相关的图片/视频/新闻等。所有这些服务的结果会被有选择地合并成结果页面；我们把这种模型称之为"全局搜索(universal search)"。处理一次全局搜索查询，总计需要上千台机器，涉及多种服务。而且web搜索的用户对延时很敏感，而任何一个子系统的性能差了都可能导致延时。工程师如果只看总体耗时的话，他能知道出问题了，但是他猜不到是哪个系统出问题、为什么出问题。**首先，工程师可能无法准确知道到底调用了哪些服务**；每周我们都会添加新的服务，用于实现用户需求、提升性能或安全性。**其次，工程师不可能对每个服务的内部都了如指掌**；每个服务都是由不同的团队开发维护的。**第三，服务和服务器可能被许多不同的客户端调用**，所以性能问题有可能是其他应用造成的。举个例子，前端服务器可能要处理多个不同的请求类型，或者存储系统在被多个应用共享时效率最高，例如Bigtable。

上面描述的场景就对Dapper提出了两条最基本的要求：大范围部署(uniquitous deployment)、持续监控(continuous monitoring)。即便只有很小一部分系统没有被监控到，跟踪系统的作用也会大打折扣，所以大范围部署非常重要。另外，应该始终开启监控，因为通常来说异常系统行为很难重现，甚至根本无法重现。这两条基本要求提出了三个具体的设计目标：

- **低消耗(Low overhead)**：跟踪系统对在线服务的性能影响应该做到可忽略不计。对于一些高度优化过的服务，监控系统的一点小消耗都会很显眼，都可能迫使部署团队不得不关停跟踪系统。
- **应用透明(Application-level transparency)**：程序员应该不需要感知到跟踪系统。如果跟踪系统要求应用开发者的配合才能生效，那么这个跟踪系统就太脆弱了，经常会由于应用侵入代码的bug或者疏忽导致无法正常工作，这就违反了"大范围部署"的要求。这在我们这种快速开发的环境下尤为重要。
- **可扩展性(Scalability)**：需要能处理Google在未来几年的服务和集群规模。

另外一个设计目标是生成跟踪数据后要很快可用于分析：最好是在一分钟内。尽管一个能处理几小时前数据的跟踪分析系统已经很有用了，但是能分析最新数据的话会让我们能对生产环境的异常情况作出快速反应。

我们通过把Dapper跟踪植入的核心代码限制在线程调用、控制流、RPC库代码中，实现了真正的应用透明这个最具挑战性的目标。使用自适应的采样（见4.4节），我们做到了可扩展性、降低性能损耗。最终的系统还包括收集跟踪数据的代码、可视化数据的工具、用于分析大规模跟踪数据的库和API。尽管开发人员有时通过Dapper就足以找出性能问题的根源，但Dapper并不会替代所有其他的工具。我们发现Dapper的数据往往侧重于性能排查，所以其他工具也有自己的用处（so that other tools can be applied locally）。

### 1.1 贡献总结

之前已有一些优秀的文章探讨了分布式系统跟踪工具的设计空间，其中Pinpoint[9]、Magpie[3]和X-Trace[12]和Dapper最为相关。这些系统倾向于在开发过程中的早期就写成研究报告，而此时还没有机会明确地评估重要的设计选型。Dapper已经在生产环境中被大型系统应用好几年了，我们认为本文最适合的侧重点是讨论我们在Dapper开发过程中有哪些收获、我们的设计决策是如何制定的、它在哪些方面最有用。Dapper作为一个开发性能分析工具的平台以及作为一个监控工具，其价值是我们可以在回顾评估中找到一些意想不到的产出。

虽然Dapper的许多高层理念和Pinpoint， Magpie等其他系统是共通的，但是我们的实现包含了一系列新的贡献。举个例子，我们发现要想降低消耗的话采样就必不可少，尤其是在高度优化后的对latency非常敏感的web服务中。或许最令人惊讶的是，我们发现即便1/1000的采样率，已经能为跟踪数据的通用用例提供足够多的信息了。

Dapper的另一个重要特征是我们实现的应用透明程度非常高。我们将侵入代码限制在足够底层，所以即便是像Google web搜索这样的大型分布式系统也能进行跟踪，而无需额外的注解。虽然由于我们的部署环境具有一定的同质性，所以更容易实现应用透明这个目标，但是我们的结果也论证了实现透明性的充分条件。

## 2. Dapper的分布式跟踪

分布式服务的跟踪系统需要记录在一次请求后系统完成的所有工作的信息。举个例子，图-1展示了拥有5台服务器的服务：一个前端服务器A，两个中间层B和C，两个后端服务器D和E。当用户发起请求到前端服务器A之后，会发送两个RPC调用到B和C。B马上会返回结果，但是C还需要继续调用后端服务器D和E，然后返回结果给A，A再响应最初的请求。对这个请求来说，一个简单的分布式跟踪系统需要记录每台机器上的每次信息发送和接收的信息标识符和时间戳。

![dapper-1_tree](/images/post/2019/dapper/dapper-1_tree.png)

*(图-1. 由用户请求X发起的穿过一个简单服务系统的请求路径。字母标识的节点表示分布式系统中的处理过程)*

为了能将信息聚合到一起以便人们能将所有记录信息关联到一个初始请求(如图1中的请求X)，我们提出了两种解决方案：黑盒模式和基于标注的监控模式。**黑盒模式**假定除了上面描述的信息记录之外无需任何额外的信息，而使用统计回归技术来推断关联关系。基于标注的模式则要求应用程序或中间件显式地将每个记录关联到一个全局ID，从而将这些信息记录关联回初始请求。黑盒模式比基于标注的模式更加轻便，但是它依赖统计推断，所以需要更多的数据以便获取足够的准确性。很明显，基于标注的模式关键缺点是需要有代码侵入。在我们的环境中，由于所有应用系统都使用相同的线程模型、控制流和RPC系统，所以我们可以将代码侵入限制在小规模的公用库中，以此实现对开发人员有效透明的监控系统。

我们倾向于认为Dapper的跟踪是一个嵌入式的RPC树。然而，我们的核心数据模型并不局限于特定的RPC框架；我们也能跟踪例如Gmail SMTP会话、来自外界的HTTP请求、对SQL服务器的查询等行为。正式一点说，Dapper跟踪模型使用了`树`、`span`和`标注`。

### 2.1 跟踪树与span

在Dapper跟踪树中，树节点是基本单元，我们称之为`span`。节点之间的连线表示span与其`父span`之间的关系。虽然节点在整个跟踪树中的位置是独立的，但span也是一个简单的时间戳日志，其中编码了这个span的开始时间、结束时间、RPC时间数据、以及0或多个应用程序相关的标注，我们将在2.3节中讨论这些内容。

![dapper-2_span](/images/post/2019/dapper/dapper-2_span.png)

*(图-2. Dapper跟踪树中5个span的临时关系)*

图2阐释了spans是如何构造成更大的跟踪结构的。Dapper为每个span记录了一个可读的`span name`、`span id`和`parent id`，这样就能重建出一次分布式跟踪过程中不同span之间的关系。没有parent id的span被称为`根span`。一次特定跟踪的所有相关span会共享同一个通用的`trace id` (trace id在图中没有绘出)。所有这些ID可以是全局唯一的64位整数。在一个典型的Dapper跟踪中，我们希望每个RPC对应一个span，每一个组件层对应跟踪树上的一个层级。

![dapper-3_span_detail](/images/post/2019/dapper/dapper-3_span_detail.png)

*(图-3. span的详细视图)*

图3给出了Dapper跟踪span中记录的事件的更详细视图。这个span标示图2中更长的那次"Helper.Call" RPC调用。Dapper的RPC库记录下了span的开始时间和结束时间、RPC的计时信息。如果应用程序负责人选择用他们自己的标注来注释这次跟踪(例如图中的"foo")，那么这些信息也会跟随span的其他信息一起记录下来。

要着重强调的是，一个span中的信息可能来自多个不同的主机；实际上，每个RPC span都包含client和server端的标注，这使得`二主机span`是最常见的情况。由于client和server的时间戳来自不同的主机，所以我们需要注意时钟偏差。在我们的分析工具中，我们利用了如下事实：RPC client发送请求总是会先于server接受到请求，对于server响应也是如此。这样一来，RPC server端的span时间戳就有了下限和上限。

### 2.2 性能测量点 Instrumention points

通过对部分通用库进行性能测量，Dapper能够做到在对应用程序开发者零干扰的情况下进行分布式路径跟踪：

- 当一个线程处理被跟踪的控制路径时，Dapper会把一个`trace context(跟踪上下文)`存储到ThreadLocal中。跟踪上下文是一个小而容易复制的容器，里面包含了trace id和span id等span属性。
- 当计算过程是延迟调用或异步执行时，多数Google开发者会使用一个通用的控制流程库来构造回调函数，并用线程池或其他executor来执行回调。Dapper确保所有的回调都会存储其创建者的跟踪上下文，而当执行回调时这个跟踪上下文会关联到合适的线程上。通过这种方式，Dapper用于重建跟踪的ID也能透明地用于异步控制流程。
- Google进程间的通讯几乎都是建立在一个用C++和Java开发的RPC框架上。我们在这个框架上进行性能测量，定义了所有RPC调用相关的span。被跟踪的RPC调用的span id和trace id会从客户端传送到服务端。对于这种在Google内广泛使用的基于RPC的系统来说，这是一个非常必要的性能测量点。当非RPC通讯框架发展成熟并找到其用户群后，我们会计划对非RPC通信框架进行性能测量。

Dapper的跟踪数据是语言无关的，生产环境中的许多跟踪结合了C++和Java进程中的数据。在3.2节我们将讨论我们在实践中达到了何种程度的应用程序透明。

### 2.3 标注 Annotation

上述性能测量点足够推导出复杂分布式系统的跟踪细节，这使得Dapper的核心功能也适用于那些不可修改的Google应用程序。然而，Dapper也允许应用程序开发者添加额外的信息，以丰富Dapper的跟踪数据，从而帮助监控更高级别的系统行为，或者帮助调试问题。我们允许用户通过一个简单的API来定义带时间戳的标注，其核心代码如图4所示。这些标注支持任意内容。为了保护Dapper用户不至于意外加入太多日志，每个跟踪span都可配置一个标注量的上限。应用程序级别的标注是不能替代结构化的span信息以及RPC信息的。

![dapper-4_annotation](/images/post/2019/dapper/dapper-4_annotation.png)

*(图-4. Dapper标注API在C++和Java中的通用使用模式)*

除了简单的文本标注，Dapper也支持key-value map的标注，给开发者提供更强的跟踪能力，例如维护计数器、记录二进制消息、传输任意用户自定义的数据。这些key-value标注可用于在分布式跟踪上下文中定义应用程序相关的对等类（equivalence classes）。

### 2.4 采样 Sampling

Dapper的一个关键设计目标是低损耗，因为如果一个新工具的价值还未证实，而对性能有影响的话，服务运维人员是不会愿意去部署这个工具的。而且，我们还想要允许开发人员使用标注API，而无需担心额外的损耗。我们同时也发现web服务确实对性能测量的损耗很敏感。所以，除了把Dapper的基本性能测量损耗限制得尽可能小，我们还通过仅记录一部分跟踪信息，来进一步降低损耗。我们将在4.4节详细讨论这种跟踪采样模式。

### 2.5 跟踪收集

![dapper-5_collection](/images/post/2019/dapper/dapper-5_collection.png)

(图-5. Dapper收集管道概览)

Dapper的跟踪记录和收集管道氛围三个阶段(如图5)。首先，把span数据写入(1)到本地日志文件。然后Dapper守护进程从所有生产主机中将他们拉取出来(2)，最终写入(3)到Dapper的Bigtable仓库中。Bigtable中的行表示一次跟踪，列表示一个span。Bigtable对稀疏表格布局的支持正适合这种情况，因为每个跟踪都可能有任意多个span。跟踪数据收集即将应用程序二进制数据传输到中央仓库，其延迟中位数小于15秒。98分位延迟呈现双峰形；大约75%时间里，98分位延迟小于2分钟，但是在另外25%时间里可能会涨到几小时。

Dapper还提供了一个API来简化对仓库中跟踪数据的访问。Google开发者利用这个API来构造通用的或者特定应用程序的分析工具。5.1节将介绍这个API的使用。

#### 2.5.1 out-of-band跟踪收集

Dapper系统在请求树`带外(out-of-band)`进行日志跟踪与收集。这样做有两个原因：首先，带内收集模式（in-band collection scheme）通过RPC响应头回传跟踪数据，这会影响应用的网络动态。Google的许多大型系统里，一次跟踪有几千个span的情况并不少见。而即便是在大型分布式跟踪的根节点附近，RPC响应仍然是相当小的：通常小于10K。在这种情况下，带内跟踪数据会影响应用数据，并且使后续的分析结果产生偏差。其次，带内收集模式假定所有RPC调用时完美嵌套的。而我们发现许多中间件系统会在其后端服务返回最终结果前，返回一个结果给其调用者。带内收集系统不能适用于这种非嵌套的分布式执行模式。

### 2.6 安全和隐私考虑

记录RPC payload信息会丰富Dapper的跟踪能力，因为分析工具可能能从payload数据中找到导致性能异常的模式。然而在某些情况下，payload数据会包含不应该暴露给非授权内部用户的信息，包括正在调试性能的工程师。

由于安全和隐私是不可忽略的问题，所以Dapper存储了RPC方法名，但不会存储任何payload数据。相反，应用级别的标注则提供了一个方便的可选机制：应用开发人员可以选择将那些对以后分析有用的任何数据关联到一个span上。

Dapper还提供了一些设计者没料到的安全性好处。例如Dapper通过跟踪公开的安全协议参数，用来监控应用是否满足认证或加密的安全策略。Dapper还可以提供信息以确保系统是否执行了预期的基于策略的隔离，例如承载敏感数据的应用不与未授权的系统组件交互。这种方法可比代码审核强多了。

## 3. Dapper的部署状况

我们把Dapper作为生产环境跟踪系统超过两年了。本节我们将汇报Dapper系统的状态，着重讲解Dapper如何很好地满足大范围部署、应用透明等目标的。

### 3.1 Dapper运行时库

Dapper代码中最关键的部分也许就是对基础RPC、线程、控制流库的性能测量了，包含创建span、采样以及记录到本地磁盘。我们的代码不仅需要轻量，还需要稳定、健壮，因为它与海量应用连接，维护和bug修复是很困难的。C++性能测量的核心代码少于1000行，而Java中则少于800行。key-value标注的代码实现额外有500行代码。

### 3.2 生产环境覆盖率

Dapper的渗透率可以通过两方面来衡量：其一是可以创建Dapper跟踪的生产环境进程比率（即与Dapper性能测量运行时库连接的那些），其二是运行Dapper跟踪收集守护进程的生产环境机器比率。Dapper守护进程是我们基本机器镜像的一部分，所以实际上它在Google的每台服务器上都有。很难确定Dapper-ready进程精确比率，因为那些不产生跟踪信息的进程是对Dapper不可见的。尽管如此，因为Dapper性能测量库几乎无处不在，我们估么着几乎每一个Google生产环境进程都支持跟踪。

在有些情况下Dapper不能正确地跟踪控制流程。这通常是由于使用了非标准的控制流程，或是由于Dapper错误地将因果关系归到无关的事件上。Dapper提供了一个简单的库作为一种变通方法，可以帮助开发者手动控制跟踪的传播。目前有40个C++应用和33个Java应用需要手工的跟踪传播，这对总计几千个应用来说只是很小的一部分。还有很小一部分程序使用的是没有性能测量的通讯库(例如通过原生TCP Socket或者SOAP RPC)，所以是不支持Dapper跟踪的。但如果真的需要的话，这些应用也可以做到支持Dapper。[How?]

为了生产环境的安全性，Dapper跟踪是可以被关闭的。实际上在早期它默认是关闭的，直到我们对Dapper的稳定性和低损耗有信心之后，我们才把它开启了。Dapper团队偶尔会进行审计检查配置文件的变化，找到那些关闭了跟踪配置的服务。这种变化很少见，并且通常是因为担心监控的消耗。经过对实际消耗的进一步调查和衡量，发现其消耗已经很小了，所以现在这些改动都已经被回退回去了。

### 3.2 跟踪标注的使用

程序员们喜欢用应用程序指定的标注来作为一种分布式调试日志文件，或者通过应用程序的特定功能来对跟踪进行分类。例如所有Bigtable的请求都标注了访问的表名。目前Dapper中70%的span和90%的trace都至少有一个应用指定的标注。

有41个Java应用和68个C++应用都添加了自定义的标注以便更好地理解span内的行为。值得注意的是Java开发者在每个span上加的标注比C++开发者更多，这也许是因为Java的负载更接近最终用户；这类应用经常处理更广的请求，所以控制路径也相对更复杂。



## 4 管理跟踪损耗

跟踪系统的成本是由于生成追踪和收集数据造成的系统性能下降，以及用来存储和分析跟踪数据的资源量。尽管你可以说一个有价值的跟踪系统即便造成一点性能损耗也是值得的，但是我们相信如果基线损耗达到可以忽略的程度，那么一定会对跟踪系统的最初推广大有裨益。

本节我们将展示Dapper性能测量操作的消耗、跟踪收集的消耗、以及Dapper对生产环境负载的影响。同时还会介绍Dapper的适应性采样机制是如何帮助我们平衡低损耗与代表性的。

### 4.1 跟踪生成的损耗

跟踪生成的损耗是Dapper性能影响中最重要的部分，因为收集和分析可以在紧急情况下被关闭。Dapper运行库生成跟踪的消耗最重要的原因是创建销毁span和标注、以及记录到本地磁盘以便后续的收集。非根span的创建和销毁平均需要176纳秒，而根span则需要204纳秒。这个差别是因为要对根span分配全局唯一trace id的时间。

如果一个span没有被采样的话，那么额外标注的成本则几乎可以忽略不计，只需Dapper运行时在ThreadLocal中查找，平均花费9纳秒。而如果这个span被采样的话，对span进行字符串标注（见图4）则平均需要花费40纳秒。这些数据都是基于2.2GHz x86服务器测量得出的。

Dapper运行时库最昂贵的操作就是写入本地磁盘了，不过这个损耗可以大大减少，因为每个磁盘都会合并对多个日志文件写入操作，并且相对于被跟踪的应用系统来说是异步执行的。尽管如此，日志写入对高吞吐量系统仍然可能有可见的性能影响，尤其是当所有请求都都被跟踪时。在4.3节我们对一次Web搜索过程中生成跟踪的损耗进行了量化。

### 4.2 跟踪收集的损耗

读出本地的跟踪数据也会对正在监控的负载产生影响。表1展示了在高于实际负载的测试情况下，Dapper守护进程CPU使用率的最坏情况。

| Process Count (per host) | Data Rate (per process) | Daemon CPU Usage (single CPU core) |
| -----------------------: | ----------------------: | ---------------------------------: |
|                       25 |                 10K/sec |                             0.125% |
|                       10 |                200K/sec |                             0.267% |
|                       50 |                  2K/sec |                             0.130% |

*(表-1. Dapper守护进程在负载测试中中CPU资源使用率)*

Dapper守护进程在跟踪收集过程中，对生产环境单核CPU的占用率从未超过0.3%，并且内存占用也很小。同时我们把Dapper守护进程在内核scheduler中的优先级限制到尽可能最低，以防在高负载机器上出现CPU竞争。

Dapper对网络资源的消耗也轻量，我们仓库中每个span平均只有426byte。Dapper跟踪数据在Google生产环境中占用的网络流量小于0.01%。

### 4.3 对生产环境负载的影响

高吞吐量的在线服务对每个请求都会用到大量的机器，这种在线服务最有需求进行高效的跟踪；他们会生成大量的跟踪数据，同时也对性能影响是最敏感的。在表2中我们用web搜索集群作为例子，通过调整采样率，来测量Dapper对平均延迟和吞吐量的性能影响。

| Sampling frequency | Avg. Latency (% change) | Avg. Throughput (% change) |
| -----------------: | ----------------------: | -------------------------: |
|                1/1 |                   16.3% |                     -1.48% |
|                1/2 |                   9.40% |                     -0.73% |
|                1/4 |                   6.38% |                     -0.30% |
|                1/8 |                   4.12% |                     -0.23% |
|               1/16 |                   2.12% |                     -0.08% |
|             1/1024 |                  -0.20% |                     -0.06% |

*(表-2. Dapper采样频率对Web搜索集群延迟及吞吐量的影响。延迟及吞吐量的实验误差分别为2.5%和0.15%)*

可以看到，虽然对吞吐量的影响不是很明显，但为了避免明显的延迟，跟踪采样还是非常有必要的。然而，当采样率小于1/16时的延迟和吞吐量损失是在实验误差范围内的。实践中，我们发现对于高容量服务来说，即便把采样率设为1/1024这样低，仍然能够得到足够多的跟踪数据。保持Dapper的性能损耗基线极其低是很重要的，因为这就能为应用程度提供一个宽松的环境来使用完整的标注API，而无需担心性能损失。使用低采样率还有一个额外的好处，可以让主机磁盘中的数据在被垃圾回收之前能持久化更长的时间，这就让收集组件有了更多的灵活性。

### 4.4 适应性采样

Dapper对于任何给定进程的损耗是与单位时间内进程跟踪的数目成正比的。Dapper的第一个生产版本在Google的几乎所有进程上使用同一个采样率，每1024个候选中平均采样一个。这个简单的方案对高吞吐量在线服务是有效的，因为大多数我们感兴趣的事件仍然会经常出现并被捕捉到。

然而，低流量的服务在这种低采样率下就可能会错失重要的事件，而更高采样率带来的性能损耗是可接受的。针对这种系统的解决方案是覆盖默认采样率，而这就需要手工干预，我们不想在Dapper中出现这种手工干预。

我们正在部署一种适应性的采样机制，不使用统一的采样率，而使用使用单位时间内的期望采样率。这样，低流量负载会自动提高采样率，而高流量负载则会自动降低采样率，从而掌控损耗。实际采样率会和跟踪数据一起记录下来；这有利于在基于Dapper数据的分析工具中精准使用采样率。

### 4.5 应对激进采样

Dapper新用户往往觉得低采样率（高流量服务中通常会低于0.01%）会干扰他们的分析。我们在Google中应用的经验让我们相信，对于高吞吐量服务来说，激进采样并不会妨碍最重要的那些分析。如果一个重要的执行模式在这种系统中出现过一次，那么就会出现上千次。每秒请求几十次而不是上万次的那些低流量服务则可以承受跟踪每一个请求；这驱动着我们往适应性采样方向前进。

### 4.6 收集过程中的额外采样

上述采样机制用来尽量减少与Dapper运行时库协作的应用程序中的性能损耗。Dapper团队还需要控制写入中央仓库的数据量，为此我们引入了第二轮采样。

目前我们生产集群每天产生超过1TB的采样跟踪数据。Dapper用户希望跟踪数据从生产进程中记录下来后最少保留两周时间。逐渐增长的跟踪数据带来了好处，同时Dapper仓库的机器和磁盘存储成本也在增加，我们需要作出权衡。对请求的高采样率还会使得Dapper收集器接近Dapper Bigtable仓库的写入吞吐量极限。







为了维持物质资源的需求和渐增的Bigtable的吞吐之间的灵活性，我们在收集系统自身上增加了额外的采样率的支持。我们充分利用所有span都来自一个特定的跟踪并分享同一个跟踪ID这个事实，虽然这些span有可能横跨了数千个主机。对于在收集系统中的每一个span，我们用hash算法把跟踪ID转成一个标量Z，这里0<=Z<=1。如果Z比我们收集系统中的系数低的话，我们就保留这个span信息，并写入到Bigtable中。反之，我们就抛弃他。通过在采样决策中的跟踪ID，我们要么保存、要么抛弃整个跟踪，而不是单独处理跟踪内的span。我们发现，有了这个额外的配置参数使管理我们的收集管道变得简单多了，因为我们可以很容易地在配置文件中调整我们的全局写入率这个参数。

如果整个跟踪过程和收集系统只使用一个采样率参数确实会简单一些，但是这就不能应对快速调整在所有部署的节点上的运行期采样率配置的这个要求。我们选择了运行期采样率，这样就可以优雅的去掉我们无法写入到仓库中的多余数据，我们还可以通过调节收集系统中的二级采样率系数来调整这个运行期采样率。Dapper的管道维护变得更容易，因为我们就可以通过修改我们的二级采样率的配置，直接增加或减少我们的全局覆盖率和写入速度。

5. 通用的Dapper工具
几年前，当Dapper还只是个原型的时候，它只能在Dapper开发者耐心的支持下使用。从那时起，我们逐渐迭代的建立了收集组件，编程接口，和基于Web的交互式用户界面，帮助Dapper的用户独立解决自己的问题。在本节中，我们会总结一下哪些的方法有用，哪些用处不大，我们还提供关于这些通用的分析工具的基本的使用信息。

5.1	Dapper Depot API
Dapper的“Depot API”或称作DAPI，提供在Dapper的区域仓库中对分布式跟踪数据一个直接访问。DAPI和Dapper跟踪仓库被设计成串联的，而且DAPI意味着对Dapper仓库中的元数据暴露一个干净和直观的的接口。我们使用了以下推荐的三种方式去暴露这样的接口：

通过跟踪ID来访问：DAPI可以通过他的全局唯一的跟踪ID读取任何一次跟踪信息。
批量访问：DAPI可以利用的MapReduce提供对上亿条Dapper跟踪数据的并行读取。用户重写一个虚拟函数，它接受一个Dapper的跟踪信息作为其唯一的参数，该框架将在用户指定的时间窗口中调用每一次收集到的跟踪信息。
索引访问：Dapper的仓库支持一个符合我们通用调用模板的唯一索引。该索引根据通用请求跟踪特性(commonly-requested trace features)进行绘制来识别Dapper的跟踪信息。因为跟踪ID是根据伪随机的规则创建的，这是最好的办法去访问跟某个服务或主机相关的跟踪数据。
所有这三种访问模式把用户指向不同的Dapper跟踪记录。正如第2.1节所述的，Dapper的由span组成的跟踪数据是用树形结构建模的，因此，跟踪数据的数据结构，也是一个简单的由span组成遍历树。Span就相当于RPC调用，在这种情况下，RPC的时间信息是可用的。带时间戳的特殊的应用标注也是可以通过这个span结构来访问的。

选择一个合适的自定义索引是DAPI设计中最具挑战性的部分。压缩存储要求在跟踪数据种建立一个索引的情况只比实际数据小26%，所以消耗是巨大的。最初，我们部署了两个索引：第一个是主机索引，另一个是服务名的索引。然而，我们并没有找到主机索引和存储成本之间的利害关系。当用户对每一台主机感兴趣的时候，他们也会对特定的服务感兴趣，所以我们最终选择把两者相结合，成为一个组合索引，它允许以服务名称，主机，和时间戳的顺序进行有效的查找。

5.1.1 DAPI在Google内部的使用
DAPI在谷歌的使用有三类：使利用DAPI的持续的线上Web应用，维护良好的可以在控制台上调用的基于DAPI的工具，可以被写入，运行、不过大部分已经被忘记了的一次性分析工具。我们知道的有3个持久性的基于DAPI的应用程序，8个额外的按需定制的基于DAPI分析工具，以及使用DAPI框架构建的约15~20一次性的分析工具。在这之后的工具就这是很难说明了，因为开发者可以构建、运行和丢弃这些项目，而不需要Dapper团队的技术支持。

5.2	Dapper的用户接口
绝大多数用户使用发生在基于web的用户交互接口。篇幅有限，我们不能列出每一个特点，而只能把典型的用户工作流在图6中展示。


图6

用户描述的他们关心的服务和时间，和其他任何他们可以用来区分跟踪模板的信息（比如，span的名称）。他们还可以指定与他们的搜索最相关的成本度量(cost metric)(比如，服务响应时间)。
一个关于性能概要的大表格，对应确定的服务关联的所有分布式处理图表。用户可以把这些执行图标排序成他们想要的，并选择一种直方图去展现出更多的细节。
一旦某个单一的分布式执行部分被选中后，用户能看到关于执行部分的的图形化描述。被选中的服务被高亮展示在该图的中心。
在生成与步骤1中选中的成本度量(cost metric)维度相关的统计信息之后，Dapper的用户界面会提供了一个简单的直方图。在这个例子中，我们可以看到一个大致的所选中部分的分布式响应时间分布图。用户还会看到一个关于具体的跟踪信息的列表，展现跟踪信息在直方图中被划分为的不同区域。在这个例子中，用户点击列表种第二个跟踪信息实例时，会在下方看到这个跟踪信息的详细视图(步骤5)。
绝大多数Dapper的使用者最终的会检查某个跟踪的情况，希望能收集一些信息去了解系统行为的根源所在。我们没有足够的空间来做跟踪视图的审查，但我们使用由一个全局时间轴（在上方可以看到），并能够展开和折叠树形结构的交互方式，这也很有特点。分布式跟踪树的连续层用内嵌的不同颜色的矩形表示。每一个RPC的span被从时间上分解为一个服务器进程中的消耗（绿色部分）和在网络上的消耗（蓝色部分）。用户Annotation没有显示在这个截图中，但他们可以选择性的以span的形式包含在全局时间轴上。
为了让用户查询实时数据，Dapper的用户界面能够直接与Dapper每一台生产环境下的服务器上的守护进程进行交互。在该模式下，不可能指望能看到上面所说的系统级的图表展示，但仍然可以很容易基于性能和网络特性选取一个特定的跟踪。在这种模式下，可在几秒钟内查到实时的数据。

根据我们的记录，大约有200个不同的Google工程师在一天内使用的Dapper的UI;在一周的过程中，大约有750-1000不同的用户。这些用户数，在新功能的内部通告上，是按月连续的。通常用户会发送特定跟踪的连接，这将不可避免地在查询跟踪情况时中产生很多一次性的，持续时间较短的交互。

6. 经验
Dapper在Google被广泛应用，一部分直接通过Dapper的用户界面，另一部分间接地通过对Dapper API的二次开发或者建立在基于api的应用上。在本节中，我们并不打算罗列出每一种已知的Dapper使用方式，而是试图覆盖Dapper使用方式的“基本向量”，并努力来说明什么样的应用是最成功的。

6.1	在开发中使用Dapper
Google AdWords系统是围绕一个大型的关键词定位准则和相关文字广告的数据库搭建的。当新的关键字或广告被插入或修改时，它们必须通过服务策略术语的检查（如检查不恰当的语言，这个过程如果使用自动复查系统来做的话会更加有效）。

当轮到从头重新设计一个广告审查服务时，这个团队迭代的从第一个系统原型开始使用Dapper，并且，最终用Dapper一直维护着他们的系统。Dapper帮助他们从以下几个方面改进了他们的服务：

性能：开发人员针对请求延迟的目标进行跟踪，并对容易优化的地方进行定位。Dapper也被用来确定在关键路径上不必要的串行请求--通常来源于不是开发者自己开发的子系统--并促使团队持续修复他们。
正确性：广告审查服务围绕大型数据库系统搭建。系统同时具有只读副本策略（数据访问廉价）和读写的主策略（访问代价高）。Dapper被用来在很多种情况中确定，哪些查询是无需通过主策略访问而可以采用副本策略访问。Dapper现在可以负责监控哪些主策略被直接访问，并对重要的系统常量进行保障。
理解性：广告审查查询跨越了各种类型的系统，包括BigTable—之前提到的那个数据库，多维索引服务，以及其他各种C++和Java后端服务。Dapper的跟踪用来评估总查询成本，促进重新对业务的设计，用以在他们的系统依赖上减少负载。
测试：新的代码版本会经过一个使用Dapper进行跟踪的QA过程，用来验证正确的系统行为和性能。在跑测试的过程中能发现很多问题，这些问题来自广告审查系统自身的代码或是他的依赖包。
广告审查团队广泛使用了Dapper Annotation API。Guice[13]开源的AOP框架用来在重要的软件组件上标注“@Traced”。这些跟踪信息可以进一步被标注，包含：重要子路径的输入输出大小、基础信息、其他调试信息，所有这些信息将会额外发送到日志文件中。

同时，我们也发现了一些广告审查小组在使用方面的不足。比如：他们想根据他们所有跟踪的Annotation信息，在一个交互时间段内进行搜索，然而这就必须跑一个自定义的MapReduce或进行每一个跟踪的手动检查。另外，在Google还有一些其他的系统在也从通用调试日志中收集和集中信息，把那些系统的海量数据和Dapper仓库整合也是有价值的。

总的来说，即便如此，广告审查团队仍然对Dapper的作用进行了以下评估，通过使用Dapper的跟踪平台的数据分析，他们的服务延迟性已经优化了两个数量级。

6.1.1 与异常监控的集成
Google维护了一个从运行进程中不断收集并集中异常信息报告的服务。如果这些异常发生在Dapper跟踪采样的上下文中，那么相应的跟踪ID和span的ID也会作为元数据记录在异常报告中。异常监测服务的前端会提供一个链接，从特定的异常信息的报告直接导向到他们各自的分布式跟踪。广告审查团队使用这个功能可以了解bug发生的更大范围的上下文。通过暴露基于简单的唯一ID构建的接口，Dapper平台被集成到其他事件监测系统会相对容易。

6.2	解决延迟的长尾效应
考虑到移动部件的数量、代码库的规模、部署的范围，调试一个像全文搜索那样服务（第1节里提到过）是非常具有挑战性的。在这节，我们描述了我们在减轻全文搜索的延迟分布的长尾效应上做的各种努力。Dapper能够验证端到端的延迟的假设，更具体地说，Dapper能够验证对于搜索请求的关键路径。当一个系统不仅涉及数个子系统，而是几十个开发团队的涉及到的系统的情况下，端到端性能较差的根本原因到底在哪，这个问题即使是我们最好的和最有经验的工程师也无法正确回答。在这种情况下，Dapper可以提供急需的数据，而且可以对许多重要的性能问题得出结论。


图7：全局搜索的跟踪片段，在不常遇到高网络延迟的情况下，在沿着关键路径的端到端的请求延迟，如图所示。

在调试延迟长尾效应的过程中，工程师可以建立一个小型库，这个小型库可以根据DAPI跟踪对象来推断关键路径的层级结构。这些关键路径的结构可以被用来诊断问题，并且为全文搜索提供可优先处理的预期的性能改进。Dapper的这项工作导致了下列发现：

在关键路径上的短暂的网络性能退化不影响系统的吞吐量，但它可能会对延迟异常值产生极大的影响。在图7中可以看出，大部分的全局搜索的缓慢的跟踪都来源于关键路径的网络性能退化。
许多问题和代价很高的查询模式来源于一些意想不到的服务之间的交互。一旦发现，往往容易纠正它们，但是Dapper出现之前想找出这些问题是相当困难的。
通用的查询从Dapper之外的安全日志仓库中收取，并使用Dapper唯一的跟踪ID，与Dapper的仓库做关联。然后，该映射用来建立关于在全局搜索中的每一个独立子系统都很慢的实例查询的列表。
6.3	推断服务依赖
在任何给定的时间内，Google内部的一个典型的计算集群是一个汇集了成千上万个逻辑“任务”的主机，一套的处理器在执行一个通用的方法。Google维护着许多这样的集群，当然，事实上，我们发现在一个集群上计算着的这些任务通常依赖于其他的集群上的任务。由于任务们之间的依赖是动态改变的，所以不可能仅从配置信息上推断出所有这些服务之间的依赖关系。不过，除了其他方面的原因之外，在公司内部的各个流程需要准确的服务依赖关系信息，以确定瓶颈所在，以及计划服务的迁移。Google的可称为“Service Dependencies”的项目是通过使用跟踪Annotation和DAPI MapReduce接口来实现自动化确定服务依赖归属的。

Dapper核心组件与Dapper跟踪Annotation一并使用的情况下，“Service Dependencies”项目能够推算出任务各自之间的依赖，以及任务和其他软件组件之间的依赖。比如，所有的BigTable的操作会加上与受影响的表名称相关的标记。运用Dapper的平台，Service Dependencies团队就可以自动的推算出依赖于命名的不同资源的服务粒度。

6.4	不同服务的网络使用率
Google投入了大量的人力和物力资源在他的网络结构上。从前网络管理员可能只关注独立的硬件信息、常用工具及以及搭建出的各种全局网络鸟瞰图的dashboard上的信息。网络管理员确实可以一览整个网络的健康状况，但是，当遇到问题时，他们很少有能够准确查找网络负载的工具，用来定位应用程序级别的罪魁祸首。

虽然Dapper不是设计用来做链路级的监控的，但是我们发现，它是非常适合去做集群之间网络活动性的应用级任务的分析。Google能够利用Dapper这个平台，建立一个不断更新的控制台，来显示集群之间最活跃的网络流量的应用级的热点。此外，使用Dapper我们能够为昂贵的网络请求提供指出的构成原因的跟踪，而不是面对不同服务器之间的信息孤岛而无所适从。建立一个基于Dapper API的dashboard总共没花超过2周的时间。

6.5	分层和共享存储系统
在Google的许多存储系统是由多重独立复杂层级的分布式基础设备组成的。例如，Google的App Engine[5]就是搭建在一个可扩展的实体存储系统上的。该实体存储系统在基于BigTable上公开某些RDBMS功能。 BigTable的同时使用Chubby[7]（分布式锁系统）及GFS。再者，像BigTable这样的系统简化了部署，并更好的利用了计算资源。

在这种分层的系统，并不总是很容易确定最终用户资源的消费模式。例如，来自于一个给定的BigTable单元格的GFS大信息量主要来自于一个用户或是由多个用户产生，但是在GFS层面，这两种明显的使用场景是很难界定。而且，如果缺乏一个像Dapper一样的工具的情况下，对共享服务的竞争可能会同样难于调试。

第5.2节中所示的Dapper的用户界面可以聚合那些调用任意公共服务的多个客户端的跟踪的性能信息。这就很容易让提供这些服务的源从多个维度给他们的用户排名。（例如，入站的网络负载，出站的网络负载，或服务请求的总时间）

6.6	Dapper的救火能力(Firefighting)
对于一些“救火”任务，Dapper可以处理其中的一部分。“救火”任务在这里是指一些有风险很高的在分布式系统上的操作。通常情况下，Dapper用户当正在进行“救火”任务时需要使用新的数据，并且没有时间写新的DAPI代码或等待周期性的报告运行。

对于那些高延迟，不，可能更糟糕的那些在正常负载下都会响应超时的服务，Dapper用户界面通常会把这些延迟瓶颈的位置隔离出来。通过与Dapper守护进程的直接通信，那些特定的高延迟的跟踪数据轻易的收集到。当出现灾难性故障时，通常是没有必要去看统计数据以确定根本原因，只查看示例跟踪就足够了(因为前文提到过从Dapper守护进程中几乎可以立即获得跟踪数据)。

但是，如在6.5节中描述的共享的存储服务，要求当用户活动过程中突然中断时能尽可能快的汇总信息。对于事件发生之后，共享服务仍然可以利用汇总的的Dapper数据，但是，除非收集到的Dapper数据的批量分析能在问题出现10分钟之内完成，否则Dapper面对与共享存储服务相关的“救火”任务就很难按预想的那般顺利完成。

7. 其他收获
虽然迄今为止，我们在Dapper上的经验已经大致符合我们的预期，但是也出现了一些积极的方面是我们没有充分预料到的。首先，我们获得了超出预期的Dapper使用用例的数量，对此我们可谓欢心鼓舞。另外，在除了几个的在第6节使用经验中提到过的一些用例之外，还包括资源核算系统，对指定的通讯模式敏感的服务的检查工具，以及一种对RPC压缩策略的分析器，等等。我们认为这些意想不到的用例一定程度上是由于我们向开发者以一种简单的编程接口的方式开放了跟踪数据存储的缘故，这使得我们能够充分利用这个大的多的社区的创造力。除此之外，Dapper对旧的负载的支持也比预期的要简单，只需要在程序中引入一个用新版本的重新编译过的公共组件库(包含常规的线程使用，控制流和RPC框架)即可。

Dapper在Google内部的广泛使用还为我们在Dapper的局限性上提供了宝贵的反馈意见。下面我们将介绍一些我们已知的最重要的Dapper的不足：

合并的影响：我们的模型隐含的前提是不同的子系统在处理的都是来自同一个被跟踪的请求。在某些情况下，缓冲一部分请求，然后一次性操作一个请求集会更加有效。（比如，磁盘上的一次合并写入操作）。在这种情况下，一个被跟踪的请求可以看似是一个大型工作单元。此外，当有多个追踪请求被收集在一起，他们当中只有一个会用来生成那个唯一的跟踪ID，用来给其他span使用，所以就无法跟踪下去了。我们正在考虑的解决方案，希望在可以识别这种情况的前提下，用尽可能少的记录来解决这个问题。
跟踪批处理负载：Dapper的设计，主要是针对在线服务系统，最初的目标是了解一个用户请求产生的系统行为。然而，离线的密集型负载，例如符合MapReduce[10]模型的情况，也可以受益于性能挖潜。在这种情况下，我们需要把跟踪ID与一些其他的有意义的工作单元做关联，诸如输入数据中的键值（或键值的范围），或是一个MapReduce shard。
寻找根源：Dapper可以有效地确定系统中的哪一部分致使系统整个速度变慢，但并不总是能够找出问题的根源。例如，一个请求很慢有可能不是因为它自己的行为，而是由于队列中其他排在它前面的(queued ahead of)请求还没处理完。程序可以使用应用级的annotation把队列的大小或过载情况写入跟踪系统。此外，如果这种情况屡见不鲜，那么在ProfileMe[11]中提到的成对的采样技术可以解决这个问题。它由两个时间重叠的采样率组成，并观察它们在整个系统中的相对延迟。
记录内核级的信息：一些内核可见的事件的详细信息有时对确定问题根源是很有用的。我们有一些工具，能够跟踪或以其他方式描述内核的执行，但是，想用通用的或是不那么突兀的方式，是很难把这些信息到捆绑到用户级别的跟踪上下文中。我们正在研究一种妥协的解决方案，我们在用户层面上把一些内核级的活动参数做快照，然后绑定他们到一个活动的span上。
8. 相关产品
在分布式系统跟踪领域，有一套完整的体系，一部分系统主要关注定位到故障位置，其他的目标是针对性能进行优化。 Dapper确实被用于发现系统问题，但它更通常用于探查性能不足，以及提高全面大规模的工作负载下的系统行为的理解。

与Dapper相关的黑盒监控系统，比如Project5[1]，WAP5[15]和Sherlock[2]，可以说不依赖运行库的情况下，黑盒监控系统能够实现更高的应用级透明。黑盒的缺点是一定程度上不够精确，并可能在统计推断关键路径时带来更大的系统损耗。

对于分布式系统监控来说，基于Annotation的中间件或应用自身是一个可能是更受欢迎的解决办法.拿Pip[14]和Webmon[16]系统举例，他们更依赖于应用级的Annotation，而X-Trace[12]，Pinpoint[9]和Magpie[3]大多集中在对库和中间件的修改。Dapper更接近后者。像Pinpoint，X-Trace，和早期版本的Magpie一样，Dapper采用了全局标识符把分布式系统中各部分相关的事件联系在一起。和这些系统类似，Dapper尝试避免使用应用级Annotation，而是把的植入隐藏在通用组件模块内。Magpie放弃使用全局ID，仍然试图正确的完成请求的正确传播，他通过采用应用系统各自写入的事件策略，最终也能精确描述不同事件之间关系。但是目前还不清楚Magpie在实际环境中实现透明性这些策略到底多么有效。 X-Trace的核心Annotation比Dapper更有野心一些，因为X-Trace系统对于跟踪的收集，不仅在跟踪节点层面上，而且在节点内部不同的软件层也会进行跟踪。而我们对于组件的低性能损耗的要求迫使我们不能采用X-Trace这样的模型，而是朝着把一个请求连接起来完整跟踪所能做到的最小代价而努力。而Dapper的跟踪仍然可以从可选的应用级Annotation中获益。

9. 总结
在本文中，我们介绍Dapper这个Google的生产环境下的分布式系统跟踪平台，并汇报了我们开发和使用它的相关经验。 Dapper几乎在部署在所有的Google系统上，并可以在不需要应用级修改的情况下进行跟踪，而且没有明显的性能影响。Dapper对于开发人员和运维团队带来的好处，可以从我们主要的跟踪用户界面的广泛使用上看出来，另外我们还列举了一些Dapper的使用用例来说明Dapper的作用，这些用例有些甚至都没有Dapper开发团队参与，而是被应用的开发者开发出来的。

据我们所知，这是第一篇汇报生产环境下分布式系统跟踪框架的论文。事实上，我们的主要贡献源于这个事实：论文中回顾的这个系统已经运行两年之久。我们发现，结合对开发人员提供简单API和对应用系统完全透明来增强跟踪的这个决定，是非常值得的。

我们相信，Dapper比以前的基于Annotation的分布式跟踪达到更高的应用透明度，这一点已经通过只需要少量人工干预的工作量得以证明。虽然一定程度上得益于我们的系统的同质性，但它本身仍然是一个重大的挑战。最重要的是，我们的设计提出了一些实现应用级透明性的充分条件，对此我们希望能够对更错杂环境下的解决方案的开发有所帮助。

最后，通过开放Dapper跟踪仓库给内部开发者，我们促使更多的基于跟踪仓库的分析工具的产生，而仅仅由Dapper团队默默的在信息孤岛中埋头苦干的结果远达不到现在这么大的规模，这个决定促使了设计和实施的展开。

Acknowledgments
We thank Mahesh Palekar, Cliff Biffle, Thomas Kotzmann, Kevin Gibbs, Yonatan Zunger, Michael Kleber, and Toby Smith for their experimental data and feedback about Dapper experiences. We also thank Silvius Rus for his assistance with load testing. Most importantly, though, we thank the outstanding team of engineers who have continued to develop and improve Dapper over the years; in order of appearance, Sharon Perl, Dick Sites, Rob von Behren, Tony DeWitt, Don Pazel, Ofer Zajicek, Anthony Zana, Hyang-Ah Kim, Joshua MacDonald, Dan Sturman, Glenn Willen, Alex Kehlenbeck, Brian McBarron, Michael Kleber, Chris Povirk, Bradley White, Toby Smith, Todd Derr, Michael De Rosa, and Athicha Muthitacharoen. They have all done a tremendous amount of work to make Dapper a day-to-day reality at Google.
