<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Distributed System | Alpha's Programming Notes]]></title>
  <link href="http://alphawang.github.io/blog/categories/distributed-system/atom.xml" rel="self"/>
  <link href="http://alphawang.github.io/"/>
  <updated>2022-08-17T22:34:41+08:00</updated>
  <id>http://alphawang.github.io/</id>
  <author>
    <name><![CDATA[Alpha Wang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Apache Pulsar 与 Apache Kafka 之对比分析]]></title>
    <link href="http://alphawang.github.io/blog/kafka-versus-pulsar/"/>
    <updated>2022-08-17T21:35:10+08:00</updated>
    <id>http://alphawang.github.io/blog/kafka-versus-pulsar</id>
    <content type="html"><![CDATA[<blockquote><p>本文可能是全网最好的对比 Kafka 与 Pulsar 的文章之一。</p>

<ul>
<li><p>翻译自 <a href="https://learning.oreilly.com/library/view/apache-pulsar-versus/9781492076551/ch01.html#what_is_apache_pulsar">https://learning.oreilly.com/library/view/apache-pulsar-versus/9781492076551/ch01.html#what_is_apache_pulsar</a> ，原作者 Chris Bartholomew。</p></li>
<li><p>如有错漏，欢迎提 PR 至 <a href="https://github.com/AlphaWang/Translation-Apache-Pulsar-Versus-Apache-Kafka">https://github.com/AlphaWang/Translation-Apache-Pulsar-Versus-Apache-Kafka</a></p></li>
</ul>
</blockquote>

<p>Apache Kafka 是一种广泛使用的发布订阅（pub-sub）消息系统，起源于 LinkedIn，并于 2011 年成为 Apache 软件基金会（ASF）项目。而近年来，Apache Pulsar 逐渐成为 Kafka 的重要替代品，原本被 Kafka 占据的使用场景正越来越多地转向 Pulsar。在本报告中，我们将回顾 Kafka 与 Pulsar 之间的主要区别，并深入了解 Pulsar 为何势头如此强劲。</p>

<!--more-->


<h1>什么是 Apache Pulsar？</h1>

<p>与 Kafka 类似，Apache Pulsar 也是起源于一家互联网公司内部，用于解决自己特有的问题。2015 年，雅虎的工程师们需要一个可以在商业硬件上提供低延迟的 pub-sub 消息系统，并且需要支持扩展到数百万个主题，并为其处理的所有消息提供强持久性保证。</p>

<p>雅虎的工程师们评估了当时已有的解决方案，但无一能满足所有需求。于是他们决定着手构建一个全新的 pub-sub 消息系统，使之可以支持他们的全球应用程序，例如邮箱、金融、体育以及广告。他们的解决方案后来演化成 Apache Pulsar，自 2016 年就开始在雅虎的生产环境中运行。</p>

<h1>架构对比</h1>

<p>让我们先从架构角度对比 Kafka 和 Pulsar 这两个系统。由于在开发 Pulsar 的时候 Kafka 已经广为人知，所以 Pulsar 的作者对其架构了如指掌。你将看到这两个系统有相似之处，也有不同之处。如您所料，这是因为 Pulsar 的作者参考了 Kafka 架构中的可取之处，同时改进了其短板。既然一切都源于 Kafka，那我们就先从 Kafka 的架构开始讲起吧。</p>

<h2>Kafka</h2>

<p>Kafka 有两个主要组件：Apache ZooKeeper 和 Kafka Broker，如图 1 所示。ZooKeeper 用于服务发现、领导者选举以及元数据存储。在旧版本中，ZooKeeper 也用来存储消费者组信息，包括主题消费偏移量；但新版本不再这样了。</p>

<p><img src="/images/post/2022/pulsar-kafka/apak_0101.png" alt="img" /></p>

<p><em>图 1. Kafka 架构图</em></p>

<p>Kafka Broker 承包了 Kafka 的所有消息功能，包括终止生产者和消费者连接、接受来自生产者的新消息并将消息发送给消费者。为了保证消息持久化，Broker 还为消息提供持久化存储功能。每个 Kafka Broker 负责一组主题。</p>

<p>Kafka Broker 是有状态的。每个 Broker 都存储了相关主题的完整状态，有了这些信息 Broker 才能正常运行。如果一个 Broker 发生故障，并不是任何 Broker 都可以接管它，而是必须拥有相关主题副本的 Broker 才能接管。如果一个 Broker 负载太高，也不能简单地通过增加 Broker 来分担负载，还需要移动主题（状态）才能平衡集群中的负载。虽然 Kafka 提供了用来帮助重平衡的工具，但是要用它来运维 Kafka 集群的话，你必须了解 Kafka Broker 与其磁盘上存储的消息状态的关系才行。</p>

<p>消息计算（Serving）是指消息在生产者和消费者之间的流动，在 Kafka Broker 中消息计算与消息存储是相互耦合的。如果你的使用场景中所有消息都能被快速地消费掉，那么对消息存储的要就可能较低，而对消息计算的要求则较高。相反，如果你的使用场景中消息消费得很慢，则需要存储大量消息。在这种情况下，对消息计算的要求可能较低，而对消息存储的要求则较高。</p>

<p>由于消息的计算和存储都封装在单个 Kafka Broker 中，所以无法独立地扩展这两个维度。即便你的集群只对消息计算有较高要求，你还是得通过添加 Broker 实现扩展，也就是说不得不同时扩展消息计算和消息存储。而如果你对消息存储有较高要求，而对消息计算的要求较低，最简单的方案也是添加 Kafka Broker，也就是说还是必须同时扩展消息计算和消息存储。</p>

<p>在扩展存储的场景中，你可以在现有的 Broker 上添加更多磁盘或者增加磁盘容量，但需要小心不要创建出一些具有不同存储配置和容量的独特 Kafka Broker。这种“雪花”（Snowflake）服务器环境比具有统一配置的服务器环境要复杂得多，更难以管理。</p>

<h2>Pulsar</h2>

<p>Pulsar 架构中主要有三个组件：ZooKeeper、Pulsar Broker 和 Apache BookKeeper Bookie，如图 2 所示。与 Kafka 一样，ZooKeeper 提供服务发现、领导者选举和元数据存储。与 Kafka 不同的是，Pulsar 通过 Broker 和 BookKeeper Bookie 组件分离了消息处理计算与消息存储功能。</p>

<p><img src="/images/post/2022/pulsar-kafka/apak_0102.png" alt="img" /></p>

<p><em>图 2. Pulsar 架构图</em></p>

<p>Pulsar Broker 负责消息计算，而 BookKeeper Bookie 负责消息存储。这是一种分层架构，Pulsar Broker 处理生产者和消费者之间的消息流动，而将消息存储交给 BookKeeper 层处理。</p>

<p>得益于这种分层架构，Pulsar Broker 是无状态的，这一点与 Kafka 不同。这意味着任何 Broker 均可接管失效的 Broker。也意味着新的 Broker 上线后可以立即开始处理生产者和消费者的消息流动。为了确保 Broker 之间的负载均衡，Pulsar Broker 内置了一套负载均衡器，不断监视每个 Broker 的 CPU、内存以及网络使用情况，并据此在 Broker 之间转移主题归属以保持负载均衡。这个过程会让 Latency 小幅增加，但最终能让集群的负载达到均衡。</p>

<p>BookKeeper 作为数据存储层当然是有状态的。提供可靠消息投递保证的消息系统必须为消费者保留消息，所以消息必须持久化存储到某个地方。BookKeeper 旨在构建跨服务器的分布式日志，它是一个独立的 Apache 项目，用于多种应用中，而非仅仅是 Puslar 中。</p>

<p>BookKeeper 将日志切分成一个一个被称为 Ledger 的分片（Segment），这样就很容易在 BookKeeper Bookie 节点之间保持均衡。如果 Bookie 节点故障，一些主题会变成小于复制因子（Under Replicated）。发生这种情况后 BookKeeper 会自动从存储与其他 Bookie 中的副本复制 Ledger，从而让其恢复到复制因子，而无需等待故障 Bookie 恢复或等待其他 Bookie 上线。如果添加一个新 Bookie，它能立即开始存储已有主题的新 Ledger。由于主题或分区并不从属于某个 Bookie，所以故障恢复过程无需将主题或分区移动到新服务器。</p>

<h2>复制模型</h2>

<p>为了保证消息持久性，Kafka 和 Pulsar 都对每个消息存储多个拷贝或副本。但是他们各自使用了不同的复制模型。</p>

<p>Kafka 使用的是 Leader-Follower 复制模型。对每个主题（确切说是主题分区，稍后我们会详细解释）都会选出一个 Broker 作为 Leader。所有消息最初都写入到 Leader，然后 Follower 从 Leader 读取并复制消息，如图 3 所示。这种关系是静态的，除非 Broker 发生故障。同一主题的消息总是被写入同一组 Leader 和 Follower Broker。引入新的 Broker 并不会改变现有主题的关系。</p>

<p><img src="/images/post/2022/pulsar-kafka/apak_0103.png" alt="img" /></p>

<p><em>图 3. Kafka leader–follower 复制模型</em></p>

<p>Pulsar 使用的则是法定人数投票复制模型（quorum-vote）。Pulsar 并行写入消息的多个副本（Write Quorum）。一旦一定数量的副本被确认写入成功，则该消息被确认（Ack Quorum）。与 Leader-Follower 模型不同，Pulsar 将副本分散（或称为条带化写入）到一组存储节点（Ensemble）中，这能改善读写性能。这也意味着新的节点添加成功后，即可立即成为可写入集合的一部分，用于存储消息。</p>

<p>如图 4 所示，消息被发往 Broker，然后被切分成分片（Segment）并写入多个 Bookie 节点。这些 Bookie 节点存储分片并发送确认给 Broker。一旦 Broker 从足够多的 Bookie 节点收到足够多的分片确认，则向生产者发送消息确认。</p>

<p><img src="/images/post/2022/pulsar-kafka/apak_0104.png" alt="img" /></p>

<p><em>图 4. Pulsar quorum–vote 复制模型</em></p>

<p>由于 Broker 层是无状态的、存储层是分布式的、并且使用了法定人数投票复制模型（quorum-vote），所以与 Kafka 相比 Puslar 能更容易地处理服务器故障。只需替换掉故障服务器，Pulsar 即可自动恢复。增加新容量也更容易，只需简单的水平扩展即可。</p>

<p>而且由于计算层和存储层是分离的，所以你可以独立地扩展它们。如果对计算要求较高而对存储要求较低，那么在集群中加入更多的 Puslar Broker 即可扩展计算层。如果对存储要求很高而对计算要求很低，那么加入更多 BookKeeper Bookie 即可扩展存储层。这种独立的可扩展性意味着你可以更好地优化集群资源，避免在仅需要扩展计算能力时不得不浪费额外的存储，反之亦然。</p>

<h1>Pub–Sub 消息系统概览</h1>

<p>Kafka 和 Pulsar 支持的基础消息模式都是 pub-sub，又称发布订阅。在 pub-sub系统中，消息的发送方和接收方是解耦的，因此彼此透明。发送方（生产者）将消息发送到一个主题，而无需知道谁将接收到这些消息；接收方（消费者）订阅要接收消息的主题。发送方和接收方并不互相连接，且随时间推移可能变化。</p>

<p><img src="/images/post/2022/pulsar-kafka/apak_0105.png" alt="img" /></p>

<p><em>图 5. Pub–sub 消息模式：每个订阅者都能收到生产者发送的一条消息拷贝</em></p>

<p>Pub-sub 消息模式的一个关键特性是单个主题上可能有多个生产者与订阅者。如图 5 所示，多个发布应用可以发送消息到一个主题，多个订阅应用可以接收这些消息。重要的是，每个订阅应用都会收到自己的消息拷贝。所以如果发布了一条消息并且有 10 个订阅者，那么就会发送 10 条消息拷贝，每个订阅者收到一条消息拷贝。</p>

<p>Pub-sub 消息模式并不是什么新鲜事物，且被多种消息系统支持：RabbitMQ、ActiveMQ、IBM MQ，数不胜数。Kafka 与这些传统消息系统的区别在于，它有能力扩展到支持海量消息，同时保持一致的消息延迟。</p>

<p>与 Kafka 类似，Pulsar 也支持 pub-sub 消息模式，且也能支持海量消息且具有一致延迟。Kafka 使用消费者组来实现多个消费者接收同一消息的不同拷贝。Kafka 会与主题关联的每个消费者组发送一条消息。Pulsar 使用订阅（Subscription）来实现相同的行为， 向与主题关联的每个订阅发送一条消息。</p>

<h2>日志抽象</h2>

<p>Kafka 与传统消息系统的另一个主要区别是将日志作为处理消息的基本抽象。生产者写入主题，即写入日志；而消费者独立地读取日志。然而与传统消息系统不同，消息被读取后并不会从日志中删除。消息被持久化到日志中直至配置的时间到期。Kafka 消费者确认消息后并不会删除消息，而是提交一个偏移量值来表示它已读取了多少日志。此操作不会从日志中删除消息或以任何方式修改日志。总之，日志是不可变的。</p>

<p>为了防止日志变得无限长，日志中的消息在一段时间（保留周期）后会过期。过期的消息会从日志中删除。Kafka 默认的保留周期是七天。图 6 展示了发布的消息是如何附加到日志中，消费者如何以不同的偏移量读取它。日志中的消息到期后会过期并被删除。</p>

<p><img src="/images/post/2022/pulsar-kafka/apak_0106.png" alt="img" /></p>

<p><em>图 6. 日志抽象</em></p>

<h2>消息重放</h2>

<p>利用日志抽象可以允许多个消费者独立地读取同一个主题，同时还能支持消息重放。由于消费者只是从日志中读取消息并提交日志偏移量，因此只要将偏移量移动到较早位置就能很容易地让消费者重放已消费过的消息。支持消息重放有很多优势。例如，有 bug 的应用程序修复后可以重放之前消费过的消息以纠正其状态。在测试应用程序或开发新应用程序时，消息重放也很有用。</p>

<p>与 Kafka 类似，Pulsar 也使用日志来抽象其主题，只不过具体实现有所不同。这意味着 Puslar 也能支持消息重放。在 Puslar 中，每个订阅都有一个游标来跟踪其在主题日志中的消费位置。创建订阅的时候可以指定游标从主题的最早或最新消息开始读取。你可以将订阅游标倒回到特定消息或特定时间（例如倒回 24 小时）。</p>

<h1>传统消息模型</h1>

<p>到目前为止，我们看到 Kafka 与 Pulsar 有许多相似之处。他们都是能处理海量消息的 pub-sub 消息系统，都使用日志来抽象主题，并支持消息回放。不同之处在于对传统消息模型的支持。</p>

<p>在传统消息模型中，消息系统负责确保将消息投递给消费者。消息系统会跟踪消费者是否已经确认消息，并周期性地将未被确认的消息重新投递给消费者，直至被确认为止。一旦消息被确认，即可被删除（或标记为将来删除）。而未被确认的消息永远不会被删除，它将永远存在。而已确认的消息永远不会再发送给消费者。</p>

<p>Pulsar 利用订阅充分支持上述模型。 由于这种能力，Puslar 能够支持额外的消息模式，专注于消息如何被消费。</p>

<h1>队列与竞争消费者</h1>

<p>我们首先要分析的消息模式是传统队列模型。这种模型中队列消息代表一系列将要完成的工作（工作队列）。你可以使用单个消费者从队列中读取消息并执行工作，但更常见的做法是在多个消费者中分配工作。这种模式被称为竞争消费者模式，如图 7 所示。</p>

<p>在竞争消费者模式中，队列用于存储需要很长时间来处理的消息，例如转换视频。一条消息被发布到队列中后，被消费者读取并处理。当消息被处理完成后，消费者发回确认，然后消息从队列中删除。如果是单个消费者，则队列中的所有消息会被阻塞，直到消息被处理并确认。</p>

<p><img src="/images/post/2022/pulsar-kafka/apak_0107.png" alt="img" /></p>

<p><em>图 7. 竞争消费者：每条消息被一个消费者处理一次</em></p>

<p>为了改善整个流程并保持队列不被填满，你可以往队列中添加多个消费者。然后多个消费者会“竞争”从队列中获取消息并处理它们。如果上述视频转换的例子中我们有两个消费者，则相同时间内能处理的视频量会增加到两倍。如果这还不够快，我们可以添加更多消费者来提高吞吐量。</p>

<p>为了更有效，工作队列需要始终将消息分发给那些有能力处理队列消息的消费者。如果消费者有能力处理消息，则队列就将消息发给它。</p>

<h2>Kafka</h2>

<p>Kafka 使用消费者组和多分区来实现竞争消费者模式。Kafka 主题由一个或多个分区组成，消息被发布后通过 round-robin 或者消息 key 分布到主题分区中，随后被消费者组从主题分区中读取。</p>

<p>需要注意的是，Kafka 的一个分区一次只能被一个消费者消费。要实现竞争消费者模式，则每个消费者要有对应的分区。如果消费者数目多于分区数目，则多出来的消费者就会被闲置。举个例子，假设你的主题有两个分区，则消费者组中最多有两个活跃消费者。如果增加第三个消费者，则该消费者没有分区可以读取，所以不会竞争读取队列中的工作（消息）。</p>

<p>这意味着在创建主题时就需要明确有多少竞争消费者。当然你可以增加主题分区数，但这是相当重的变动，尤其当根据 key 分配分区时。除了 Kafka 消费者与主题的对应关系外，往消费者组中添加消费者会重平衡该主题的所有消费者，这种重平衡会暂停对所有消费者的消息投递。</p>

<p>所以说 Kafka 虽然确实支持竞争消费者消息模式，但是需要你仔细管理主题的分区数，确保添加新消费者时能真的处理消息。另外，与传统消息系统不同，Kafka 不会周期性地重新投递消息以便可以再次处理这些消息。如果想要有消息重试机制，你需要自己实现。</p>

<p>Kafka 确实比传统消息系统有个优势。竞争消费者模式的一个弊端是消息可能被乱序处理。因为竞争消费消息的多个消费者可能处理速率不同，很有可能消息会乱序处理。如果消息代表独立的工作，那么这不是什么问题。但如果消息代表像金融交易这样的事件，那有序性就很重要了。</p>

<p>由于 Kafka 分区一次只能被一个消费者消费，所以 Kafka 可以在竞争消费者模式下保证相同 key 的消息被顺序投递。如果消息是按照 key 路由到分区，则每个分区中的消息是按照发布的顺序存储的。消费者可以消费该分区并按顺序获取消息。这使得你可以扩展消费者以并行处理同时保持消息顺序，当然这一切都需要仔细的规划才行。</p>

<h2>Pulsar</h2>

<p>Pulsar 中的竞争消费者模式很容易实现，只需在主题上创建共享订阅即可。之后消费者使用此共享订阅连接到主题，消息以 round-robin 方式被连接到该订阅上的消费者消费。消费者的上线下线并不会像 Kafka 那样触发重平衡。当新的消费者上线后即开始参与 round-robin 消息接收。这是因为与 Kafka 不同，Pulsar 并不使用分区来在消费者之间分发消息，而完全通过订阅来控制。Pulsar 当然也支持分区，这一点我们稍后将讨论，但消息的消费主要是由订阅控制，而不受分区控制。</p>

<p>Pulsar 订阅会周期性地将未确认消息重新投递给消费者。不仅如此，Pulsar 还支持高级确认语义，例如单条消息确认（选择性确认）和否定确认（negative acknowledgment），这一点对工作队列场景很有用。单条消息确认允许消息不按顺序确认，所以慢速消费者不会阻塞对其他消费者投递消息，而累积确认是可能发生这种阻塞的。否定确认允许消费者将消息放回主题中，之后可以被其他消费者处理。</p>

<p>Pulsar 支持按 key 将消息路由到分区，所以也可以使用与 Kafka 一样的方案来实现竞争消费者。共享订阅这种实现方式更加简单，但是如果你想在横向扩展消费者并行处理能力的同时也保证按 key 有序，Pulsar 也是可以实现的。</p>

<h2>Pulsar 订阅模型</h2>

<p>共享订阅是 Pulsar 中实现工作队列的一种简单方式。Puslar 还支持其他订阅模型来支持多种消息消费模式：独占、 灾备、共享、键共享，如图 8 所示。</p>

<p>独占订阅模型中，不允许超过一个消费者消费主题消息。如果其他消费者尝试消费消息，则会被拒绝。如果你需要保证消息被单个消费者按顺序消费，那就使用独占订阅模型。</p>

<p>灾备订阅模型中，允许多个消费者连接到一个主题，但是在任何时间都只有一个消费者可以消费主题。这就建立了一种主备关系，一个消费者处于活跃状态，其他的处于备用状态，当活跃消费者故障时进行接管。当活跃消费者断开连接或失败，所有未确认消息会被重新投递到某个备用消费者。</p>

<p><img src="/images/post/2022/pulsar-kafka/apak_0108.png" alt="img" /></p>

<p><em>图 8. Pulsar 订阅模型：独占、灾备、共享、键共享</em></p>

<p>前文已提到，基于共享订阅模型实现的竞争消费者模式的一个弱点是消息可能被乱序处理。在 Kafka 和 Pulsar 中，都可以通过将消息按 key 路由到分区来解决。Puslar 最近推出了一种新的名为 key_shared 的订阅模型，可以更简单地解决这个问题。这种订阅模式的优点是可以按 key 有序投递消息而无需关心分区。消息可以发布到单个主题并分发给多个消费者，这跟共享订阅模型一样。不一样的是，单个消费者只会接受对应某个 key 的消息。这种订阅模型可以通过 key 按顺序投递消息而无需对主题进行分区。</p>

<h1>Pulsar：整合 Pub–Sub 与队列</h1>

<p>如我们所见，Kafka 和 Pulsar 都支持 pub-sub 消息投递。它们都使用日志来抽象主题，所以可以支持重放已被消费者处理过的消息。但是 Kafka 只能有限地支持按不同方式来消费消息，不会自动重新投递消息，也不能保证未确认的消息不会丢失。实际上，保留周期之外的所有消息无论是否被消费过都会被删除。Kafka 可以实现工作队列，但有很多事项需要注意和考虑。</p>

<p>由于这些限制，如果企业需要高性能 pub-sub 消息系统、同时需要可靠性投递保证以及传统消息模式，他们通常会在 Kafka 之外使用传统的消息系统，例如 RabbitMQ。将 Kafka 用于高性能 pub-sub 场景，而将 RabbitMQ 用于要求可靠性投递保证的场景，例如工作队列。</p>

<p>Pulsar 在单个消息系统中同时支持高性能 pub-sub 以及保证可靠性投递的传统消息模式。在 Pulsar 中实现工作队列非常简单——实际上这也是 Puslar 最开始设计时就想解决的场景。如果你正同时使用多个消息系统——使用 Kafka 处理高流量 pub-sub场景、使用 RabbitMQ 处理工作队列场景——那么可以考虑使用 Puslar 把它们整合成单个消息系统。即便最初只有一种消息场景需求，也可以直接使用 Pulsar 以应对未来可能出现的新的消息场景。</p>

<p>运维单个消息系统显然要比运维两个要更加简单、所需的 IT 和人力资源也更少。</p>

<h1>日志抽象</h1>

<p>现在我们介绍了 Kafka 与 Puslar 的高层次架构，也了解了这两个系统能实现的各种消息模式，接下来让我们更详细地了解这两个系统的底层模块。首先我们来看看日志抽象。</p>

<p>Kafka 团队的设计思路值得称赞，日志的确是实时数据交换系统的一个很好的抽象。因为日志只能追加，所以数据可以快速写入；因为日志中的数据是连续的，所以可以按照写入顺序快速读取。数据的顺序读写是很快的，而随机读写则不然。在提供数据保证的系统中，持久化存储交互都是瓶颈，而日志抽象则让这一点变得尽可能高效。Kafka 和 Pulsar 都使用日志作为其底层模块。</p>

<p>为了简单起见，下文假设 Kafka 主题是单分区的，因此下文中主题和分区是同义词。</p>

<h2>Kafka 日志</h2>

<p>在 Kafka 中，每个主题都是一个日志。日志作为单个存储单元存储在 Kafka Broker 上。虽然日志由一系列文件组成，但日志并不能拆分到多个 Broker 上，也不能拆分到同一个 Broker 的多个磁盘上。这种将整个日志作为最小存储单元的方式通常运行良好，但是当规模增大或在维护期间会很麻烦。</p>

<p>比方说日志的最大大小会受其所在磁盘容量的限制。因此，存储日志的 Broker 磁盘大小限制了主题的大小。在 Broker 上添加磁盘并不能解决问题，因为日志是最小存储单元，并不能跨磁盘拆分。唯一的选择是增加磁盘大小。这在云环境中是可行的，但如果你在物理硬件上运行 Kafka，那么增加现有磁盘的容量不是一件容易的事。</p>

<p>还有另一件麻烦的事，由于日志与其底层文件是一对一绑定的，所以在实时系统上执行维护操作是很麻烦的。如果 Broker 服务器出现故障，或者需要增加新的 Broker 来分担高负载，都需要在服务器之间拷贝大量日志文件。在保持数据实时性的同时执行大量文件拷贝会给 Kafka 集群带来很大压力。</p>

<h2>Pulsar 分布式日志</h2>

<p>与 Kafka 一样，Apache Pulsar 也使用日志抽象作为其实时消息系统的基础，每个主题在 Pulsar 中也是一个日志。然而 Pulsar 采用不一样的方式将日志写入存储。Pulsar 不是将日志作为最小存储单元存储到单个服务器，而是将日志分解为分片（或称为 Ledger），然后将 Ledger 分布到多个服务器。通过这种方式，Pulsar 创建的分布式日志驻留在多个服务器上。</p>

<p>分布式日志有许多优点。日志的最大大小不再受限于单个服务器的磁盘容量。由于分片是跨服务器分布的，所以日志可以增长到所有服务器的总存储容量一样大。增加分布式日志的容量就像往集群添加服务器一样简单。一旦新服务器上线，分布式日志即可开始使用新上线的容量来写入新的日志分片。也无需调整磁盘大小或重平衡分区来分配负载了。一旦服务器出现故障，故障恢复也很简单。故障丢失的分片可以从多个不同的服务器恢复出来，从而缩短恢复时间。</p>

<p>显而易见，让分布式日志可靠地工作起来是很困难的。这也是为什么 Puslar 要使用另一个 Apache 项目（BookKeeper）来实现分布式日志的原因。要运行 Pulsar 的话必须同时运行 Apache BookKeeper 集群。尽管这会引入运维复杂度，但是 BookKeeper 这个分布式日志的底层组件已经过验证且被广泛应用。BookKeeper 专为健壮的、低延迟的读写而设计。举个例子，BookKeeper 从架构上将写入和读取分离到单独的磁盘，这样一来慢速消费者就不会影响生产者发布新消息的性能。</p>

<p>BookKeeper 还为 Puslar 提供高持久性保证。当消息存储到 BookKeeper 时，会先刷到磁盘再给生产者发回确认；即便 BookKeeper 服务器故障，所有已确认的消息仍然能保证永久存储在磁盘上。BookKeeper 能够在保持低延迟的同时提供这种高持久性保证。</p>

<p>反观 Kafka，默认情况下定期将消息刷到磁盘。这意味着 Kafka Broker 发生故障后几乎总会导致消息丢失，因为这些消息尚未被刷到磁盘。当然，通过配置在线副本数，这些丢失的消息可以恢复；但是 BookKeeper 服务器发生类似故障的情况下，不会有数据丢失，所以也就不需要数据恢复。Kafka 也可以配置为将每条消息即时刷到磁盘，但这会带来性能损失。</p>

<h2>多级存储</h2>

<p>Pulsar 存储计算分离的另一个优点是允许在架构中引入第三层，即长期存储，又称冷存储。Pulsar 和 BookKeeper 针对快速访问主题中的消息进行了优化；然而，如果你的消息量非常大但不需要快速访问，或者只需要快速访问最新的消息即可，那么 Pulsar 允许你将这些消息推送到云对象存储，例如 AWS S3 或者 Google Cloud Storage。Pulsar 是这样实现该功能的：将主题中的老分片卸载（offload）到云提供商，然后从 bookie 本地存储中删除这些消息。</p>

<p>云对象存储比起构建高性能消息系统常用的高速 SSD 磁盘要便宜得多，因此运营成本也更低。由于云存储提供了几乎无限的存储容量，所以你不必担心超出你集群的存储容量。非常大的主题可能主要驻留在云存储中，而其他较小的主题则驻留在 bookie 节点的高速磁盘。</p>

<p>这种三层架构可以很好地适应需要永久存储消息的场景，比方说事件溯源。事件溯源是将所有状态变化都记录为事件，存储为 Pulsar 中的消息。应用的当前状态是由直到当前时间为止的整个事件历史记录确定。为了确保可以重建当前状态，你必须保存完整的事件历史。得益于持久性保证、使用分层存储实现近乎无限的存储容量，以及重放主题中所有消息的能力，Pulsar 非常适合事件溯源应用架构。</p>

<h1>分区</h1>

<p>如果你用过 Kafka，那么对分区一定很熟悉。本文中已经多次提及分区，因为这是绕不过去的。分区是 Kafka 中的一个基本概念，非常有用。Pulsar 也支持分区，但是是可选的。</p>

<h2>Kafka 分区</h2>

<p>Kafka 的所有主题都是分区的。一个主题可能只有一个分区，但必须至少有一个分区。分区在 Kafka 中是很重要的，因为分区是 Kafka 并行度的基本单元。将负载分散到多个分区即可分散到多个 Broker，单个主题的处理速度就能提高。Kafka 旨在处理高吞吐量，特别是要使用商用硬件来达到这个目的，分区在其中扮演着不可或缺的角色。</p>

<p>自 Kafka 诞生以来，商用硬件的容量不断提升。此外运行 Kafka 的 Java 虚拟机性能也不断提升。 这种硬件和软件的提升意味着现在在商用硬件上使用单分区也可以获得良好的性能。从性能角度来看，单分区主题也足以满足很多使用场景。</p>

<p>然而，正如前文所述，如果你想用多个消费者读取 Kafka 主题，就不能使用单分区。因为分区是 Kafka 生产和消费并行度的基本单元。因此即便单个分区足以满足主题的输入消息速度，你也希望使用多分区，以便将来可以选择增加多个消费者。当然，你也可以在创建主题之后再增加分区，但如果使用基于 key 的分区，这将会改变哪些 key 分配给哪些分区，从而影响分区中消息的处理顺序；而且分区会消耗资源（例如 Broker 上的文件句柄、客户端的内存占用），所以增加分区绝非一个轻量操作；另外虽然可以增加主题分区，但永远不能减少主题分区数。</p>

<p>正因为分区是 Kafka 的基础，所以要想用好 Kafka 就必须理解分区的工作原理。在创建主题时，你就需要考虑需要（或将来可能需要）多少分区数；在连接消费者时，你需要理解消费者如何与消费者组中的分区进行交互；如果你运维一个 Kafka 集群，一切都以分区级别运行，在维护和维修时，你需要以分区为中心。</p>

<h2>Pulsar 分区</h2>

<p>Pulsar 也支持分区，但是它们完全是可选的。事实上运行 Pulsar 时完全可以不使用分区。不分区的主题即可支持发布海量消息并支持多个消费者读取。如果你需要额外的性能，或需要基于 key 的有序消息消费，那么可以创建 Pulsar 分区主题。Pulsar 完全支持分区，其功能与 Kafka 大体相同。</p>

<p>Pulsar 分区被实现为一组主题的集合，用后缀来表示分区编号。例如创建一个包含三个分区的主题 <code>mytopic</code>，则会自动创建三个主题，分别名为 <code>mytopic-parition-1</code>、<code>mytopic-partition-2</code> 和 <code>mytopic-partition-3</code>。生产者可以连接到主主题 <code>mytopic</code>，根据生产者定义的路由规则将消息分发到分区主题。也可以直接发布到分区主题。同样地，消费者可以连接到主主题，也可以连接到一个分区主题。与 Kafka 一样，可以增加主题的分区数，但永远不能减少分区数。</p>

<p>由于分区在 Pulsar 中是可选的，所以 Pulsar 使用起来更加简单，尤其对于初学者来说。在 Pulsar 中你可以放心地忽略分区，除非你的使用场景需要用到分区提供的功能。这不仅简化了 Pulsar 集群的运维，也使得 Pulsar 客户端 API 更容易使用。分区是个有用的概念，不过如果你无需处理分区即可满足需求，那就有助于简化固有的复杂技术。</p>

<h1>性能</h1>

<p>Kafka 以其性能而闻名，以能够在实时环境中支持海量消息而著称。比较消息系统之间的性能有点棘手，每个系统都有性能最佳点和性能盲点，很难进行公平的比较。</p>

<p><a href="http://openmessaging.cloud/">OpenMessaging 项目</a> 是一个旨在公平比较消息系统之间性能的项目，它是一个 Linux 软件基金会协作项目。OpenMessaging 项目由多个消息系统供应商支持，其目标是为消息和流系统提供供应商中立和语言独立的标准。该项目包含一个性能测试框架，支持多种消息系统，包括 Kafka 和 Pulsar。</p>

<p>其思想是利用标准的测试框架和方法，在评估中引入一定程度的公平性。OpenMessaging 项目的所有代码都是开源的，任何人都可以运行基准测试并输出自己的结果。</p>

<p>对 Kafka 和 Pulsar 进行详细的性能分析已经超出了本文的范围。不过一些基于 OpenMessaging 基准测试框架的测试结果表明 Pulsar 的性能要优于 Kafka。</p>

<p>GigaOm 发布的一份<a href="https://oreil.ly/vGoPy">报告</a>显示：</p>

<ul>
<li>Pulsar 的最大吞吐量高出 150%</li>
<li>Pulsar 的消息延迟降低了 40%，且更加稳定</li>
<li>Pulsar 扩展性更好，在不同消息大小和分区数量下均能提供一致的结果</li>
</ul>


<p>为了验证其中一些结果，我使用 OpenMessaging 项目的基准框架对 Kafka 和 Pulsar 的延迟进行了一个 <a href="https://oreil.ly/34h_v">详细对比</a>。在这次对比中，我得出的结论是 Pulsar 能提供更加可预测的延迟。在许多情况下，Pulsar 的延迟比 Kafka 更低，尤其是在需要强持久性保证场景下，或需要大量分区的场景下。</p>

<h1>多租户</h1>

<p>租户是指可以独立使用系统的用户或用户组数量。在单租户系统中，所有的资源都是共享的，因此系统用户需要知道系统的其他用户在做什么。由于资源是共享的，必然引入争用和可能的冲突。如果多个用户组使用单租户系统，那么通常需要为系统提供多个拷贝，每个用户组使用一个拷贝，以提供隔离性和隐私。</p>

<p>在多租户系统中，不同的用户组或租户可以独立地使用系统。每个租户都是与其他租户隔离的。系统资源被各租户割据，所以每个用户都有自己的系统私有实例。我们只需提供一套系统，但每个租户都有自己的虚拟隔离环境。多租户系统可以支持多个用户组。</p>

<p>消息系统是一种核心基础设施，它最终会被多个不同的团队用于不同的项目。如果为每个团队或项目都创建一个新集群，那么运维复杂度会很高，而且也不能有效地利用资源。因此，多租户在消息系统中是一个令人向往的特性。</p>

<h2>Pulsar</h2>

<p>多租户是 Pulsar 的关键设计要求。因此 Pulsar 有多种多租户特性，让单个 Puslar 系统可以支持多个团队以及多个项目。</p>

<p>在 Pulsar 中，每个租户有自己的虚拟消息环境，与其他租户隔离开。一个租户创建的主题也与其他租户创建的主题隔离。通常，一个租户可以被一个团队或部门的所有成员使用。每个租户可以有多个命名空间。命名空间包含一组主题。不同命名空间可以包含同名的主题。命名空间可以便捷地将特定项目中的所有主题组织到一起。</p>

<p>命名空间也是一种在主题之间共享策略配置的机制。举个例子，所有需要 14 天保留周期的主题可以归到同一命名空间。在命名空间上配置该保留周期策略后，该命名空间内的所有主题都将继承这个策略。</p>

<p>当多个租户共享同一资源时，很重要的一点是要有某种机制确保所有租户都能公平地访问。需要确保一个租户不会消耗掉所有资源，导致其他租户饥饿。</p>

<p>Pulsar 有多种策略确保单个租户不至于消耗掉集群里的所有资源，例如限制消息出站速率、限制未确认消息存储以及限制消息保留期。可以在命名空间级别设置这些策略，这样各个主题组可以有不同的策略。</p>

<p>为了让多租户更好地工作，Pulsar 支持命名空间级别的授权。这意味着你可以限制对命名空间中主题的访问，可以控制谁有权限在命名空间中创建主题，以及谁有权限生产和消费这些主题。</p>

<h2>Kafka</h2>

<p>Kafka 是单租户系统，所有主题都属于一个全局命名空间。诸于保留周期等策略可以设置全局默认值，或者在单个主题上进行覆盖。但无法将相关主题组织到一起，也无法将策略应用到一组主题上。</p>

<p>关于授权，Kafka 支持访问控制列表（ACL），允许限制谁可以从主题上生产和消费。ACL 允许对集群中的授权进行细粒度的控制，可以对各种资源设置策略，比如集群、主题和消费者组；还可以指定各种特定的操作，比如创建、描述、更改和删除。除了基于用户（主体）的授权之外，还支持基于主机的授权。例如你可以允许 <code>User:Bob</code> 读写某个主题，但限制只能从 IP 地址 198.51.100.0 进行读写。而 Pulsar 没有这种细粒度的授权以及基于主机的限制，只支持少数几个操作（管理、生产、消费），并且不提供基于主机的授权。</p>

<p>尽管 Kafka 在授权控制上有更大的灵活性，但它本质上仍然是一个单租户系统。如果多个用户组使用同一个 Kafka 集群，他们需要保证主题名称不要冲突，并且 ACL 被正确应用。而多租户在 Pulsar 中是内置的，因此在不同团队和项目之间共享集群是非常简单的。</p>

<h1>跨地域复制</h1>

<p>Kafka 和 Pulsar 这类系统要实现高性能，重要一点是让其中的组件互相靠近以便有较低的互相通讯时延。这意味着 Kafka 和 Pulsar 要部署在单个数据中心，组件之间由高速网络互联。当集群内一个或多个组件（计算、存储、网络）发生故障时，集群内的消息复制机制保证免受消息丢失和服务宕机之苦。在云环境中，组件可以分布到一个数据中心（区域）内的多个可用区，以防止一个可用区发生故障。</p>

<p>但如果整个数据中心发生故障或被隔离，那么消息系统则会发生宕机（或发生灾难时丢失数据）。如果这对你来说不可接受，那么你可以使用跨地域复制。跨地域复制是指将消息复制到远端的另一个集群，发布到数据中心的每条消息都会被自动且可靠地复制到另一个数据中心。这可以防止整个数据中心发生故障。</p>

<p>跨地域复制对于全球应用程序来说也非常有用，消息从世界上某个位置生产出来，并被世界上其他地方的消费者消费。通过将消息复制到远程数据中心，可以分散负载，并提高客户端响应能力。</p>

<h2>Pulsar</h2>

<p>雅虎的团队在构建 Apache Pulsar 之初，一个关键需求就是要支持在跨地域的数据中心之间复制消息，需要确保即便整个数据中心发生故障消息仍然可用。因此对于 Pulsar 来说跨地域复制是一项核心功能，完全集成到管理界面中。可以在命名空间级别开启或关闭跨地域复制功能。管理员可以轻松配置哪些主题需要复制，哪些不需要复制。甚至生产者在发布消息时可以排除某些数据中心让它不接收消息复制。</p>

<p><img src="/images/post/2022/pulsar-kafka/apak_0109.png" alt="img" /></p>

<p><em>图 9. Active–standby 复制</em></p>

<p>Pulsar 的跨地域复制支持多种拓扑结构，例如主备（active-standby）、双活（active-active）、全网格（full mesh）以及边缘聚合（edge aggregation）。图 9 展示的是 active-standby 复制。所有消息都被发布到主数据中心（Data Center 1），然后被复制到备用数据中心（Data Center 2），如果主数据中心发生故障，客户端可以切换到备用数据中心。对于主备复制拓扑，Pulsar 新近引入了复制订阅（replicated subscription）功能，该功能在主备集群之间同步订阅状态，以便应用程序可以切换到备用数据中心并从中断的地方继续消费。</p>

<p>在主备（active–standby）复制中，客户端一次只连接到一个数据中心。而在双活（active-active）复制中，客户端连接到多个数据中心。图 10 所示的事一个全网格配置的双活复制拓扑。发布到一个数据中心的消息会被同步到其他多个数据中心。</p>

<p>图 11 所示的是边缘聚合拓扑（edge aggregation）。在此拓扑中，客户端连接到多个数据中心，这些数据中心将消息复制到中央数据中心进行处理。如果边缘数据中心处于客户端附近，那么即使中央数据中心离得很远，已发布的消息也能快速被确认。</p>

<p><img src="/images/post/2022/pulsar-kafka/apak_0110.png" alt="img" /></p>

<p><em>图 10. Active–active, full-mesh replication</em></p>

<p><img src="/images/post/2022/pulsar-kafka/apak_0111.png" alt="img" /></p>

<p><em>图 11. Edge aggregation</em></p>

<p>Pulsar 也可以进行同步跨地域复制。在典型的跨地域复制配置中，消息复制是异步完成的。生产者将消息发送到主数据中心后，消息即被持久化并确认回生产者；然后再被可靠地复制到远端数据中心。整个过程是异步的，因为消息在被复制到远端数据中心之前已向生产者确认。只要远端数据中心可用并且可以通过网络访问，这种异步复制就没有任何问题。然而，如果远端数据中心出现问题，或者网络连接变慢，那么已确认的消息就可能不能马上被复制到远端数据中心。如果主数据中心在消息被复制到远端数据中心之前发生故障，那么消息可能会丢失。</p>

<p>如果这种消息丢失对你来说不可接受，那么可以配置 Pulsar 进行同步复制。在同步复制时，消息直到被安全地存储到多个数据中心之后才会确认回生产者。由于消息要发到多数距离分散的数据中心，而数据中心之间有网络延迟，因此同步复制确认消息的时间会更长一些。不过这保证了即便整个数据中心故障也不会发生消息丢失。</p>

<p>Pulsar 有着丰富的跨地域复制功能，能支持几乎所有你能想到的配置。跨地域复制的配置和管理完全集成到 Pulsar 中，无需外部包也无需扩展。</p>

<h2>Kafka</h2>

<p>Kafka 中有多种方式可以实现跨地域复制，或者像 Kafka 文档那样称之为 mirroring。Kafka 提供了一个 MirrorMaker 工具，用来在消息生产后将其从一个集群复制到其他集群。这个工具很简单，只是将一个数据中心的 Kafka 消费者与另一个数据中心的 Kafka 生产者连接起来。它不能动态配置（改变配置后需要重启），且不支持在本地和远端集群机制同步配置信息或同步订阅信息。</p>

<p>另一个跨地域方案是由 Uber 开发并开源的 uReplicator。Uber 之所以开发 uReplicator 是为了解决 MirrorMaker 的许多缺点，提高其性能、可扩展性和可运维性。无疑 uReplicator 是更好的 Kafka 跨地域复制方案。然而它是一个独立的分布式系统，有控制器节点和工作节点，需要与 Kafka 集群并行运维。</p>

<p>Kafka 中还有用于跨地域复制的其他商业解决方案，例如 Confluent Replicator。它支持双活（active-active）复制，支持在集群间同步配置，并且比 MirrorMaker 更容易运维。它依赖于 Kafka Connect，需要与 Kafka 集群并行运维。</p>

<p>在 Kafka 中是可以实现跨地域复制的，但做起来并不简单。必须在多个方案中做出选择，需要并行运维各种工具，甚至并行运维整个分布式系统；所以说 Kafka 跨地域复制是很复杂的，尤其与 Pulsar 内置的跨地域复制能力相比。</p>

<h1>生态</h1>

<p>我们花了大量篇幅研究 Kafka 与 Pulsar 的核心技术。现在让我们放宽视野，看看围绕他们的生态系统。</p>

<h2>社区及相关项目</h2>

<p>Kafka 于 2011 年开源，而 Pulsar 于 2016 年开源。因此 Kafka 在社区构建和周边产品这方面具有五年的领先优势。Kafka 被广泛应用，已构建出了许多开源和商业产品。现在有多个商业 Kafka 发行版本可用，也有许多云提供商提供托管 Kafka 服务。</p>

<p>不仅有许多运行 Kafka 的选项，还有许多开源项目为 Kafka 提供各种客户端、工具、集成和连接器。由于 Kafka 被大型互联网公司使用，因此其中许多项目来自 Salesforce、LinkedIn、Uber 和 Shopify 这类公司。当然，Kafka 同时还有许多商业补充项目。</p>

<p>Kafka 知识也广为人知，因此很容易找到有关 Kafka 问题的答案。有很多博客文章、在线课程、超过 15,000 条 StackOverflow 问题、超过 500 位 GitHub 贡献者，以及有着丰富使用经验的大量专家。</p>

<p>Pulsar 成为开源项目的时间相对要短一些，其生态系统和社区显然还无法与 Kafka 匹敌。然而，Pulsar 从 Apache 孵化项目迅速发展为顶级项目，并且在许多社区指标上都呈现出稳步增长，例如 GitHub 贡献者、Slack 工作区成员数等。虽然 Pulsar 社区相对较小，但却热情活跃。</p>

<p>尽管如此，Kafka 在社区和相关项目上还是具有明显优势。</p>

<h2>开源</h2>

<p>Kafka 与 Pulsar 都是 ASF 开源项目。最近有很多关于开源许可证的讨论，一些开源软件供应商已经修改了他们的许可证，以防止云提供商在某些应用里使用他们的开源项目。这种做法是开源项目之间的一个重要区别。</p>

<p>一些开源项目由商业公司控制，另一些由软件基金会控制，例如 ASF。开源项目可以自由更改其软件许可证。今天他们可能会使用像 Apache 2.0 或 MIT 这样的宽松许可证，但明天就可能转向使用更加严格的许可方案。如果你正在使用由商业公司控制的开源项目，就要面对该公司出于特定商业原因更改许可证的风险。如果发生这种情况，并且你的使用方式违反了新的许可，而你又想继续获得新的更新（例如安全补丁），那么你就需要找到一个友好的项目分支，或者自己维护一个分支，或者向商业公司支付许可证费用。</p>

<p>由软件基金会控制的开源项目不太可能更改许可。使用广泛的 Apache 2.0 许可自 2004 年就已存在。即便软件基金会确实要更改其开源项目的许可证，也不太可能改成更严格，因为大多数基金会都有授权以免费提供软件且不受限制。</p>

<p>当评估开源软件时，必须牢记这一区别。Kafka 是 Apache 下的一个开源项目，Kafka 生态中的许多组件虽然是开源的，但并不受 Apache 控制，例如：</p>

<ul>
<li>除 Java 以外的所有客户端库</li>
<li>各种用于与第三方系统集成的连接器</li>
<li>监控和仪表盘工具</li>
<li>模式注册表</li>
<li>Kafka SQL</li>
</ul>


<p>Apache Pulsar 开源项目将更广泛的生态系统包含在项目之中。它将 Java、Python、Go 以及 C++ 客户端包含在主项目之中。许多连接器也是 Pulsar IO 包的一部分，例如 Aerospike、Apache Cassandra 以及 AWS Kinesis。Pulsar 自带模式注册表以及名为 Pulsar SQL 的基于 SQL 的主题查询机制。还包含仪表盘应用程序以及基于 Prometheus 的指标和告警功能。</p>

<p>由于所有这些组件都在 Pulsar 主项目中，并受 Apache 管理，其许可证不太可能变得更加严格。此外，只要项目整体得到积极维护，这些组件也会得到维护。社区对这些组件会定期进行测试，并在发布 Puslar 新版本之前修复不兼容性。</p>

<h1>总结</h1>

<p>作为 Apache Kafka 替代品，Apache Pulsar 发展势头正劲。在本文中，我们从多个维度对比了 Kafka 和 Pulsar，总结如 [表 1]。</p>

<table>
<thead>
<tr>
<th style="text-align:left;"> 对比维度                </th>
<th style="text-align:left;"> Kafka                    </th>
<th style="text-align:left;"> Pulsar                               </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;"> 架构组件                </td>
<td style="text-align:left;"> ZooKeeper、Kafka broker  </td>
<td style="text-align:left;"> ZooKeeper、Pulsar broker、BookKeeper </td>
</tr>
<tr>
<td style="text-align:left;"> 复制模型                </td>
<td style="text-align:left;"> Leader–follower          </td>
<td style="text-align:left;"> Quorum-vote                          </td>
</tr>
<tr>
<td style="text-align:left;"> 高性能 pub-sub 消息系统 </td>
<td style="text-align:left;"> 支持                     </td>
<td style="text-align:left;"> 支持                                 </td>
</tr>
<tr>
<td style="text-align:left;"> 消息重放                </td>
<td style="text-align:left;"> 支持                     </td>
<td style="text-align:left;"> 支持                                 </td>
</tr>
<tr>
<td style="text-align:left;"> 竞争消费者              </td>
<td style="text-align:left;"> 有限支持                 </td>
<td style="text-align:left;"> 支持                                 </td>
</tr>
<tr>
<td style="text-align:left;"> 传统消费模式            </td>
<td style="text-align:left;"> 不支持                   </td>
<td style="text-align:left;"> 支持                                 </td>
</tr>
<tr>
<td style="text-align:left;"> 日志抽象                </td>
<td style="text-align:left;"> 单节点                   </td>
<td style="text-align:left;"> 分布式                               </td>
</tr>
<tr>
<td style="text-align:left;"> 多级存储                </td>
<td style="text-align:left;"> 不支持                   </td>
<td style="text-align:left;"> 支持                                 </td>
</tr>
<tr>
<td style="text-align:left;"> 分区                    </td>
<td style="text-align:left;"> 必选                     </td>
<td style="text-align:left;"> 可选                                 </td>
</tr>
<tr>
<td style="text-align:left;"> 性能                    </td>
<td style="text-align:left;"> 高                       </td>
<td style="text-align:left;"> 更高                                 </td>
</tr>
<tr>
<td style="text-align:left;"> 跨地域复制              </td>
<td style="text-align:left;"> 由额外工具或外部系统实现 </td>
<td style="text-align:left;"> 内置支持                             </td>
</tr>
<tr>
<td style="text-align:left;"> 社区及相关项目          </td>
<td style="text-align:left;"> 大而成熟                 </td>
<td style="text-align:left;"> 小而成长                             </td>
</tr>
<tr>
<td style="text-align:left;"> 开源                    </td>
<td style="text-align:left;"> ASF 与其他混合           </td>
<td style="text-align:left;"> 纯 ASF                               </td>
</tr>
</tbody>
</table>


<p>我们对比了这两个系统的架构以及不同的复制模型。二者都使用 Apache ZooKeeper 以及 Broker，但 Pulsar 将 Broker 分为两层：消息计算层以及消息存储层。Pulsar 使用 Apache BookKeeper 作为其存储层。这种计算和存储分离的架构，以及 Apache BookKeeper 本身的水平扩展性，使得在 Kebernetes 等云原生环境中运行 Pulsar 变得自然而然。</p>

<p>Kafka 和 Pulsar 都使用消息复制来实现持久性。Kafka 使用 leader-follower 复制模型，而 Pulsar 使用 quorum-vote 复制模型。</p>

<p>我们分析了 Kafka 和 Pulsar 都能支持的消息模式，以及只有 Pulsar 能支持的传统消息系统（例如 RabbitMQ）的消息模式。由于 Pulsar 支持 pub-sub、流式消息模式、以及传统消息系统的基于队列的模式，因此在同时运行 Kafka 和 RabbitMQ 的组织中，可以将这些系统整合为单个 Pulsar 消息系统。如果企业想要为流式系统或传统队列部署一套消息系统，那么也可以选用 Pulsar，将来如果要支持新消息模式也能完美适配。</p>

<p>Kafka 与 Pulsar 都建立在日志抽象之上，消息被附加到不可变日志中。在 Kafka 中，日志与 Broker 节点绑定；而在 Puslar 中，日志分布在多个 Bookie 节点中。</p>

<p>分区是 Kafka 中的基础概念，但对 Pulsar 来说是可选的。这意味着 Pulsar 在处理客户端 API 以及运维上比 Kafka 更简单。</p>

<p>Pulsar 提供 Kafka 所不具备的功能，例如多级存储、内置跨地域复制、多租户等。报告表明 Pulsar 在延迟和吞吐量方面都比 Kafka 更具性能优势。Pulsar 绝大多数开源组件都由 ASF 控制，而不受商业公司控制。</p>

<p>虽然 Pulsar 的生态和社区尚不能与 Kafka 匹敌，但它在很多方面比 Kafka 更有优势。鉴于这些优势，Pulsar 作为 Kafka 替代品如此势头强劲就不足为奇了。一旦更多的人意识到它的优势，Pulsar 有望继续取得发展。</p>

<h1>致谢</h1>

<p>感谢 Sijie Guo 给予的技术评审，感谢 Jeff Bleiel 的洞察及耐心，感谢 Jess Haberman 的热情和支持。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Verify if Resilience4j Circuit Breaker Works]]></title>
    <link href="http://alphawang.github.io/blog/how-to-verify-if-resilience4j-circuit-breaker-works/"/>
    <updated>2019-12-23T17:20:44+08:00</updated>
    <id>http://alphawang.github.io/blog/how-to-verify-if-resilience4j-circuit-breaker-works</id>
    <content type="html"><![CDATA[<p>Resilience4j is a widely-used library which inspired by Hystrix, it helps with building fault tolerance distributed systems. We are using its circuit breakder module to prevent a cascade of failures when a remote service is down.</p>

<p>You can implement a circuit break based on <a href="https://resilience4j.readme.io/docs/examples">the official manual</a>, and you may want to verify if it works well or not after . Here&rsquo;re some tips</p>

<!--more-->


<h2>Circuit Breaker Configurations</h2>

<p>Before the testing, it&rsquo;s a good idea to learn the Circuit Breaker Configurations, which are critical to a successful test. See some important configurations below:</p>

<ul>
<li><code>failureRateThreshold</code>: When the failure rate is equal or greater than the threshold the CircuitBreaker transitions to open and starts short-circuiting calls.</li>
<li><code>minimumNumberOfCalls</code>: it means the minimum number of calls which are required (per sliding window period) before the CircuitBreaker can calculate the error rate. For example, if minimumNumberOfCalls is 10, then at least 10 calls must be recorded, before the failure rate can be calculated. If only 9 calls have been recorded the CircuitBreaker will not transition to open even if all 9 calls have failed.</li>
<li><code>slidingWindowSize</code> / <code>ringBufferSizeInClosedState (legacy)</code>: the size of the sliding window which is used to record the outcome of calls when the CircuitBreaker is closed.</li>
<li><code>recordExceptions</code>: A list of exceptions that are recorded as a failure and thus increase the failure rate. If you specify a list of exceptions, all other exceptions count as a success.</li>
</ul>


<h2>Mock &amp; Test</h2>

<h3>Mock Thresholds</h3>

<p>The thresholds in production enviroment are usually configured as a large value and not convenient for testing. For example,</p>

<ul>
<li><code>minimumNumberOfCalls</code> might be 100, so you have to make 100 requests to trigger the error rate calculation.</li>
<li><code>slidingWindowSize / ringBufferSizeInClosedState</code> might be 100, so you have to make another 100 requests to complete the error rate calculation.</li>
<li><code>failureRateThreshold</code> might be 90, so you have to ensure 90% requests return exception so that the circuit breaker can be triggered to transit from CLOSED to OPEN.</li>
</ul>


<p>In short, reducing those thresholds in testing environment is recommended. For example, here&rsquo;s how I set them:</p>

<ul>
<li><code>minimumNumberOfCalls</code> = 1.</li>
<li><code>slidingWindowSize</code> = 5.</li>
<li><code>failureRateThreshold</code> = 10. (another option is mock a higher exception)</li>
</ul>


<h3>Mock Exceptions</h3>

<p>Next you need to mock exception when calling the remote service so that the circuit break can recognize the call as an error, then trigger the state transition after the error rate increased and reached the threshold.</p>

<p>The first thing to notice is, not all exceptions will be counted in the error rate. So it is a good idea to figure out what kind of exception you need to mock first. If you&rsquo;ve set <code>recordExceptions</code> on CircuitBreakerConfig, those exceptions are what you need to mock!</p>

<p>For example, below snippet means only ApiServerException will be counted in the error rate.</p>

<pre><code>private static final CircuitBreakerConfig DEFAULT_CONFIG = CircuitBreakerConfig.custom()
        .failureRateThreshold(10)
        .slidingWindow(5, 1, SlidingWindowType.COUNT_BASED) 
        .recordExceptions(ApiServerException.class) 
        .build();
</code></pre>

<p>So we need to mock ApiServerException during the remote call.</p>

<pre><code>private Object invoke(Object adapter, Object fluentRequest) {
        if (count.incrementAndGet() % 2 == 0) {
            throw new ApiServerException("MOCK-EXCEPTION");
        }

        return remoteService.call();
}
</code></pre>

<blockquote><p>Note: this example mocks the exception on api client side, you can also mock on the server side.</p></blockquote>

<h3>Testing</h3>

<p>Now you can request the target API, if the circuit breaker works well, you can find the state transit from CLOSED to OPEN once the error rate reachs the theshold. You may find a log like:</p>

<pre><code>CircuitBreaker 'xx' changed state from CLOSED to OPEN
</code></pre>

<blockquote><p>Note: assumed you&rsquo;ve attached onStateTransition event.</p>

<pre><code>circuitBreaker.getEventPublisher().onStateTransition(event -&gt;
          log.warn("{}, {}", circuitBreaker.getName(), event.getStateTransition()));
</code></pre></blockquote>

<h2>Conclusion</h2>

<p>In short, reducing those thresholds in testing environment is recommended, and mock exception when calling the remote service, then you can verify the state transition by monitoring the logs.</p>

<h2>One More Thing</h2>

<p>You may found changing the thresholds is a tedious job which need to change the code and deploy, I recommend store the thresholds in a <a href="https://medium.com/@theparanoidengr/an-overview-of-config-management-in-microservices-architecture-efa815035316">Configuration Center</a>, so that you can config a lower value for testing environment without touching the code while not affect production environment.</p>

<p>Another benefit of integrating it with Configuration Center is that you can easily adjust the thresholds to fit the real world at any time.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dapper, a Large-Scale Distributed Systems Tracing Infrastructure]]></title>
    <link href="http://alphawang.github.io/blog/google-dapper-translation/"/>
    <updated>2019-03-24T12:04:46+08:00</updated>
    <id>http://alphawang.github.io/blog/google-dapper-translation</id>
    <content type="html"><![CDATA[<blockquote><p>最近在研究分布式链路跟踪系统，Google Dapper 当然是必读的论文了，目前网上能搜到一些中文翻译版，然而读下来个人感觉略生硬；这里试着在前人的肩膀上重新翻译一遍这个论文，权当是个人的学习笔记，如果同时能给其他人带来好处那就更好了。</p>

<p>同时把译文放到了 github，如您发现翻译错误或者不通顺之处，恳请提交 github PR: <a href="https://github.com/AlphaWang/alpha-dapper-translation">https://github.com/AlphaWang/alpha-dapper-translation</a></p>

<ul>
<li>原文：<a href="https://ai.google/research/pubs/pub36356">https://ai.google/research/pubs/pub36356</a></li>
<li>译文：<a href="http://alphawang.com/blog/google-dapper-translation">http://alphawang.com/blog/google-dapper-translation</a></li>
</ul>
</blockquote>

<h2>摘要</h2>

<p>现代互联网服务通常都是复杂的大规模分布式系统。这些系统由多个软件模块构成，这些软件模块可能由不同的团队开发、可能使用不同的编程语言实现、可能布在横跨多个数据中心的几千台服务器上。这种环境下就急需能帮助理解系统行为、能用于分析性能问题的工具。</p>

<p>本文将介绍 Dapper 这个在 Google 生产环境下的分布式系统跟踪服务的设计，并阐述它是如何满足在一个超大规模系统上达到<strong>低损耗</strong>（low overhead）、<strong>应用级透明</strong>（application-level transparency）、<strong>大范围部署</strong>（ubiquitous deployment）这三个需求的。Dapper 与其他一些跟踪系统的概念类似，尤其是 Magpie<sup>[3]</sup> 和X-Trace<sup>[12]</sup>，但是我们进行了一些特定的设计，使得 Dapper 能成功应用在我们的环境上，例如我们使用了采样并将性能测量（instrumentation）限制在很小一部分公用库里。</p>

<!--more-->


<p>本文的主要目的是汇报两年多以来我们构建、部署并应用 Dapper 的经历，这两年多里 Dapper 对开发和运维团队非常有用，取得了显著的成功。最初 Dapper 只是一个自包含（self-contained）的跟踪工具，后来演化成了一个监控平台并促生出许多不同的工具，有些工具甚至 Dapper 的设计者都未曾预期到。我们将介绍一些基于 Dapper 构造的分析工具，分享这些工具在 Google 内部使用的统计数据，展示一些使用场景的例子，并讨论我们学习到的经验教训。</p>

<h2>1 介绍</h2>

<p>Dapper 的目的是为了将复杂分布式系统的更多行为信息提供给 Google 开发者。这种分布式系统利用大规模的小服务器，通常对于互联网服务是一个非常经济的平台，所以很受关注。要理解在这种上下文中要的系统行为的话，就需要观察横跨不同程序和不同机器的关联行为。</p>

<p>下面基于一个 web 搜索的例子来说明这种系统需要应对哪些挑战。前端服务器将一个 web 查询分发给上百台搜索服务器，每个搜索服务器在自己的 index 中完成搜索。同时这个 web 查询可能还会被发送给多个其他子系统，进行广告处理、拼写检查、查找相关的图片/视频/新闻等。所有这些服务的结果会被有选择地合并成结果页面；我们把这种模型称之为<code>全局搜索 (universal search)</code>。处理一次全局搜索查询，总计需要上千台机器，涉及多种服务。而且 web 搜索的用户对延时很敏感，而任何一个子系统的性能差了都可能导致延时。工程师如果只看总体耗时的话，他能知道出问题了，但是他猜不到是哪个系统出问题、为什么出问题。<strong>首先，工程师可能无法准确知道到底调用了哪些服务</strong>；每周我们都会添加新的服务，用于实现用户需求、提升性能或安全性。<strong>其次，工程师不可能对每个服务的内部都了如指掌</strong>；每个服务都是由不同的团队开发维护的。<strong>第三，服务和服务器可能被许多不同的客户端调用</strong>，所以性能问题有可能是其他应用造成的。举例来说，前端服务器可能要处理多个不同的请求类型，或者类似 Bigtable 这种存储系统在被多个应用共享时效率最高。</p>

<p>上面描述的场景就对 Dapper 提出了两条最基本的要求：大范围部署 (uniquitous deployment)、持续监控 (continuous monitoring)。即便只有很小一部分系统没有被监控到，跟踪系统的作用也会大打折扣，所以大范围部署非常重要。另外，应该始终开启监控，因为通常来说异常系统行为很难重现，甚至根本无法重现。这两条基本要求提出了三个具体的设计目标：</p>

<ul>
<li><strong>低消耗 (Low overhead)</strong>：跟踪系统对在线服务的性能影响应该做到可忽略不计。对于一些高度优化过的服务，监控系统的一点小消耗都会很显眼，都可能迫使部署团队不得不关停跟踪系统。</li>
<li><strong>应用级透明 (Application-level transparency)</strong>：程序员应该不需要感知到跟踪系统。如果跟踪系统要求应用开发者的配合才能生效，那么这个跟踪系统就太脆弱了，经常会由于应用侵入代码的 bug 或者疏忽导致无法正常工作，这就违反了"大范围部署"的要求。这在我们这种快速开发的环境下尤为重要。</li>
<li><strong>可扩展性 (Scalability)</strong>：需要能处理 Google 在未来几年的服务和集群规模。</li>
</ul>


<p>另外一个设计目标是生成跟踪数据后要很快可用于分析：最好是在一分钟内。尽管一个能处理几小时前数据的跟踪分析系统已经很有用了，但是能分析最新数据的话会让我们能对生产环境的异常情况作出快速反应。</p>

<p>我们通过把 Dapper 跟踪植入的核心代码限制在线程调用、控制流以及 RPC 等库代码中，实现了真正的应用透明这个最具挑战性的目标。使用自适应的采样（见4.4节），我们做到了可扩展性、降低性能损耗。最终的系统还包括收集跟踪数据的代码、可视化数据的工具、用于分析大规模跟踪数据的库和 API。尽管开发人员有时通过 Dapper 就足以找出性能问题的根源，但 Dapper 并不会替代所有其他的工具。我们发现 Dapper 的数据往往侧重于性能排查，所以其他工具也有自己的用处。</p>

<h3>1.1 贡献总结</h3>

<p>之前已有一些优秀的文章探讨了分布式系统跟踪工具的设计空间，其中 Pinpoint<sup>[9]</sup>、Magpie<sup>[3]</sup> 和 X-Trace<sup>[12]</sup>  与 Dapper 最为相关。这些系统倾向于在开发过程中的早期就写成研究报告，而此时还没有机会明确地评估重要的设计选型。Dapper 已经在生产环境中被大型系统应用好几年了，我们认为本文最适合的侧重点是讨论我们在 Dapper 开发过程中有哪些收获、我们的设计决策是如何制定的、它在哪些方面最有用。Dapper 作为一个开发性能分析工具的平台以及作为一个监控工具，其价值是我们可以在回顾评估中找到一些意想不到的产出。</p>

<p>虽然 Dapper 的许多高层理念和 Pinpoint、Magpie 等其他系统是共通的，但是我们的实现包含了一系列新的贡献。举个例子，我们发现要想降低消耗的话采样就必不可少，尤其是在高度优化后的对延迟非常敏感的 web 服务中。或许最令人惊讶的是，我们发现即便只使用 1/1000 的采样率，已经能为跟踪数据的通用用例提供足够多的信息了。</p>

<p>Dapper 的另一个重要特征是我们实现的应用透明程度非常高。我们将性能测量限制在足够底层，所以即便是像 Google web 搜索这样的大型分布式系统也能进行跟踪，而无需额外的注解。虽然由于我们的部署环境具有一定的同质性，所以更容易实现应用透明这个目标，但是我们的结果也论证了实现透明性的充分条件。</p>

<h2>2 Dapper 的分布式跟踪</h2>

<p>分布式服务的跟踪系统需要记录在一次请求后系统完成的所有工作的信息。举个例子，图-1展示了拥有 5 台服务器的服务：一个前端服务器 A，两个中间层 B 和 C，两个后端服务器 D 和 E。当用户发起请求到前端服务器 A 之后，会发送两个 RPC 调用到 B 和 C。B 马上会返回结果，但是 C 还需要继续调用后端服务器 D 和 E，然后返回结果给 A，A 再响应最初的请求。对这个请求来说，一个简单的分布式跟踪系统需要记录每台机器上的每次信息发送和接收的信息标识符和时间戳。</p>

<p><img src="/images/post/2019/dapper/dapper-1_tree.png" alt="dapper-1_tree" /></p>

<p><em>(图-1. 由用户请求X 发起的穿过一个简单服务系统的请求路径。字母标识的节点表示分布式系统中的处理过程)</em></p>

<p>为了能将信息聚合到一起以便人们能将所有记录信息关联到一个初始请求（如图1中的请求 X），我们提出了两种解决方案：<code>黑盒监控模式</code> 和 <code>基于标注的监控模式</code>。<strong>黑盒模式</strong><sup>[1, 15, 2] </sup>假定除了上面描述的信息记录之外无需任何额外的信息，而使用统计回归技术来推断关联关系。<strong>基于标注的模式</strong><sup>[3, 12, 9, 16]</sup> 则要求应用程序或中间件显式地将每个记录关联到一个全局 ID，从而将这些信息记录关联回初始请求。黑盒模式比基于标注的模式更加轻便，但是它依赖统计推断，所以需要更多的数据以便获取足够的准确性。很明显，基于标注的模式关键缺点是需要有代码侵入。在我们的环境中，由于所有应用系统都使用相同的线程模型、控制流和 RPC 系统，所以我们可以将性能测量限制在小规模的公用库中，以此实现对开发人员有效透明的监控系统。</p>

<p>我们倾向于认为 Dapper 的跟踪是一个嵌入式的 RPC 树。然而，我们的核心数据模型并不局限于特定的RPC 框架；我们也能跟踪例如 Gmail SMTP 会话、来自外界的 HTTP 请求、对 SQL 服务器的查询等行为。正式一点说，Dapper 跟踪模型使用了<code>树</code>、<code>span</code>和 <code>标注</code>。</p>

<h3>2.1 跟踪树与span</h3>

<p>在 Dapper 跟踪树中，树节点是基本单元，我们称之为 <code>span</code>。节点之间的连线表示 span 与其<code>父span</code> 之间的关系。虽然节点在整个跟踪树中的位置是独立的，但 span 也是一个简单的时间戳日志，其中编码了这个 span 的开始时间、结束时间、RPC 时间数据、以及0或多个应用程序相关的标注，我们将在 2.3 节讨论这些内容。</p>

<p><img src="/images/post/2019/dapper/dapper-2_span.png" alt="dapper-2_span" /></p>

<p><em>(图-2. Dapper 跟踪树中5个 span 的因果和实时关系)</em></p>

<p>图2 阐释了 span 是如何构造成更大的跟踪结构的。Dapper 为每个 span 记录了一个可读的<code>span name</code>、<code>span id</code>和 <code>parent id</code>，这样就能重建出一次分布式跟踪过程中不同 span 之间的关系。没有parent id 的 span被称为 <code>根span</code>。一次特定跟踪的所有相关 span 会共享同一个通用的<code>trace id</code> （trace id在图中没有绘出）。所有这些 ID 可能是唯一的 64 位整数。在一个典型的 Dapper 跟踪中，我们希望每个 RPC 对应一个 span，每一个组件层对应跟踪树上的一个层级。</p>

<p><img src="/images/post/2019/dapper/dapper-3_span_detail.png" alt="dapper-3_span_detail" /></p>

<p><em>(图-3. span 的详细视图)</em></p>

<p>图3 给出了 Dapper 跟踪 span 中记录的事件的更详细视图。这个 span 标示图 2 中更长的那次 <code>Helper.Call</code> RPC 调用。Dapper 的 RPC 库记录下了 span 的开始时间和结束时间、RPC 的计时信息。如果应用程序负责人选择用他们自己的标注来注释这次跟踪（例如图中的<code>foo</code>），那么这些信息也会跟随 span 的其他信息一起记录下来。</p>

<p>要着重强调的是，一个 span 中的信息可能来自多个不同的主机；实际上，每个 RPC span 都包含 client和 server 端的标注，这使得<code>二主机span (two host span)</code>是最常见的情况。由于 client 和 server 的时间戳来自不同的主机，所以我们需要注意时钟偏差。在我们的分析工具中，我们利用了如下事实：RPC client 发送请求总是会先于 server 接受到请求，对于 server 响应也是如此。这样一来，RPC server 端的 span 时间戳就有了下限和上限。</p>

<h3>2.2 性能测量点 Instrumention points</h3>

<p>通过对部分通用库进行性能测量，Dapper 能够做到在对应用程序开发者零干扰的情况下进行分布式路径跟踪：</p>

<ul>
<li>当一个线程处理被跟踪的控制路径时，Dapper 会把一个<code>跟踪上下文（trace context）</code>存储到ThreadLocal 中。跟踪上下文是一个小而容易复制的容器，里面包含了 trace id 和 span id 等 span属性。</li>
<li>当计算过程是延迟调用或异步执行时，多数 Google 开发者会使用一个通用的控制流程库来构造回调函数，并用线程池或其他 executor 来执行回调。Dapper 确保所有的回调都会存储其创建者的跟踪上下文，而当执行回调时这个跟踪上下文会关联到合适的线程上。通过这种方式，Dapper 用于重建跟踪的 ID 也能透明地用于异步控制流程。</li>
<li>Google 进程间的通讯几乎都是建立在一个用 C++ 和 Java 开发的 RPC 框架上。我们在这个框架上进行性能测量，定义了所有 RPC 调用相关的 span。被跟踪的 RPC 调用的 span id 和 trace id 会从客户端传送到服务端。对于这种在Google内广泛使用的基于RPC的系统来说，这是一个非常必要的性能测量点。我们计划当非 RPC 通讯框架发展成熟并找到其用户群后，再对非 RPC 通信框架进行性能测量。</li>
</ul>


<p>Dapper 的跟踪数据是语言无关的，生产环境中的许多跟踪结合了 C++ 和 Java 进程中的数据。在 3.2 节我们将讨论我们在实践中达到了何种程度的应用程序透明。</p>

<h3>2.3 标注 Annotation</h3>

<p>上述性能测量点足够推导出复杂分布式系统的跟踪细节，这使得 Dapper 的核心功能也适用于那些不可修改的 Google 应用程序。然而，Dapper 也允许应用程序开发者添加额外的信息，以丰富 Dapper 的跟踪数据，从而帮助监控更高级别的系统行为，或者帮助调试问题。我们允许用户通过一个简单的 API 来定义带时间戳的标注，其核心代码如图4 所示。这些标注支持任意内容。为了保护 Dapper 用户不至于意外加入太多日志，每个跟踪 span 都可配置一个标注量的上限。应用程序级别的标注是不能替代结构化的 span 信息以及 RPC 信息的。</p>

<p><img src="/images/post/2019/dapper/dapper-4_annotation.png" alt="dapper-4_annotation" /></p>

<p><em>(图-4. Dapper 标注 API 在 C++ 和 Java 中的通用使用模式)</em></p>

<p>除了简单的文本标注，Dapper 也支持 key-value map 的标注，给开发者提供更强的跟踪能力，例如维护计数器、记录二进制消息、传输任意用户自定义的数据。这些 key-value 标注可用于在分布式跟踪上下文中定义应用程序相关的对等类（equivalence classes）。</p>

<h3>2.4 采样 Sampling</h3>

<p>Dapper 的一个关键设计目标是低损耗，因为如果一个新工具的价值还未证实，而对性能有影响的话，服务运维人员是不会愿意去部署这个工具的。而且，我们还想要允许开发人员使用标注 API，而无需担心额外的损耗。我们同时也发现 web 服务确实对性能测量的损耗很敏感。所以，除了把 Dapper 的基本性能测量损耗限制得尽可能小，我们还通过仅记录一部分跟踪信息，来进一步降低损耗。我们将在 4.4 节详细讨论这种跟踪采样模式。</p>

<h3>2.5 跟踪收集</h3>

<p><img src="/images/post/2019/dapper/dapper-5_collection.png" alt="dapper-5_collection" /></p>

<p><em>(图-5. Dapper 收集管道概览)</em></p>

<p>Dapper 的跟踪记录和收集管道分为三个阶段（如图5）。首先，把 span 数据写入(1) 到本地日志文件。然后 Dapper 守护进程从所有生产主机中将他们拉取出来(2)，最终写入(3) 到 Dapper 的 Bigtable 仓库中。Bigtable 中的行表示一次跟踪，列表示一个 span。Bigtable 对稀疏表格布局的支持正适合这种情况，因为每个跟踪都可能有任意多个 span。跟踪数据收集即将应用程序二进制数据传输到中央仓库，其延迟中位数小于 15 秒。98 分位延迟呈现双峰形；大约 75% 时间里，98 分位延迟小于 2 分钟，但是在另外 25% 时间里可能会涨到几小时。</p>

<p>Dapper 还提供了一个 API 来简化对仓库中跟踪数据的访问。Google 开发者利用这个API来构造通用的或者特定应用程序的分析工具。5.1 节将介绍这个 API 的使用。</p>

<h4>2.5.1 带外（out-of-band）跟踪收集</h4>

<p>Dapper 系统在请求树 <code>带外(out-of-band)</code> 进行日志跟踪与收集。这样做有两个原因：首先，带内收集模式（in-band collection scheme）通过 RPC 响应头回传跟踪数据，这会影响应用的网络动态。Google 的许多大型系统里，一次跟踪有几千个 span 的情况并不少见。而即便是在大型分布式跟踪的根节点附近，RPC 响应仍然是相当小的：通常小于 10K。在这种情况下，带内跟踪数据会影响应用数据，并且使后续的分析结果产生偏差。其次，带内收集模式假定所有 RPC 调用时完美嵌套的。而我们发现许多中间件系统会在其后端服务返回最终结果前，返回一个结果给其调用者。带内收集系统不能适用于这种非嵌套的分布式执行模式。</p>

<h3>2.6 安全和隐私考虑</h3>

<p>记录 RPC payload 信息会丰富 Dapper 的跟踪能力，因为分析工具可能能从 payload 数据中找到导致性能异常的模式。然而在某些情况下，payload 数据可能会包含一些信息，这些信息不应该暴露给非授权内部用户，包括正在调试性能的工程师。</p>

<p>由于安全和隐私是不可忽略的问题，所以 Dapper 存储了 RPC 方法名，但不会存储任何 payload 数据。相反，应用级别的标注则提供了一个方便的可选机制：应用开发人员可以选择将那些对以后分析有用的任何数据关联到一个 span 上。</p>

<p>Dapper 还提供了一些设计者没料到的安全性好处。例如 Dapper 通过跟踪公开的安全协议参数，用来监控应用是否满足认证或加密的安全策略。Dapper 还可以提供信息以确保系统是否执行了预期的基于策略的隔离，例如承载敏感数据的应用不与未授权的系统组件交互。这种方法可比代码审核强多了。</p>

<h2>3 Dapper 的部署状况</h2>

<p>我们把 Dapper 作为生产环境跟踪系统超过两年了。本节我们将汇报 Dapper 系统的状态，着重讲解Dapper 如何很好地满足大范围部署、应用级透明等目标的。</p>

<h3>3.1 Dapper 运行时库</h3>

<p>Dapper 代码中最关键的部分也许就是对基础 RPC、线程、控制流库的性能测量了，包含创建 span、采样以及记录到本地磁盘。我们的代码不仅需要轻量，还需要稳定、健壮，因为它与海量应用连接，维护和 bug 修复是很困难的。我们的C++ 性能测量的核心代码少于 1000 行，而 Java 代码则少于 800 行。key-value 标注的代码实现额外有 500 行代码。</p>

<h3>3.2 生产环境覆盖率</h3>

<p>Dapper 的渗透率可以通过两方面来衡量：其一是可以<strong>产生</strong> Dapper 跟踪的生产环境进程比率（即与 Dapper 性能测量运行时库连接的那些），其二是运行 Dapper 跟踪<strong>收集</strong>守护进程的生产环境机器比率。Dapper 守护进程是我们基本机器镜像的一部分，所以实际上它在 Google 的每台服务器上都有。很难确定 Dapper-ready 进程精确比率，因为那些不产生跟踪信息的进程是对 Dapper 不可见的。尽管如此，因为 Dapper 性能测量库几乎无处不在，我们估么着几乎每一个 Google 生产环境进程都支持跟踪。</p>

<p>在有些情况下 Dapper 不能正确地跟踪控制流程。这通常是由于使用了非标准的控制流程，或是由于Dapper 错误地将因果关系归到无关的事件上。Dapper 提供了一个简单的库作为一种变通方法，可以帮助开发者手动控制跟踪的传播。目前有 40 个 C++ 应用和 33 个 Java 应用需要手工的跟踪传播，这对总计几千个应用来说只是很小的一部分。还有很小一部分程序使用的是没有性能测量的通讯库（例如通过原生 TCP Socket 或者 SOAP RPC），所以是不支持 Dapper 跟踪的。但如果真的需要的话，这些应用也可以做到支持 Dapper。</p>

<p>为了生产环境的安全性，Dapper 跟踪是可以被关闭的。实际上在早期它默认是关闭的，直到我们对Dapper 的稳定性和低损耗有信心之后，我们才把它开启了。Dapper 团队偶尔会进行审计检查配置文件的变化，找到那些关闭了跟踪配置的服务。这种变化很少见，并且通常是因为担心监控的消耗。经过对实际消耗的进一步调查和衡量，发现其消耗已经很小了，所以现在这些改动都已经被回退回去了。</p>

<h3>3.3 跟踪标注的使用</h3>

<p>程序员们喜欢用应用程序特定的标注来作为一种分布式调试日志文件，或者通过应用程序的特定功能来对跟踪进行分类。例如所有 Bigtable 的请求都标注了访问的表名。目前 Dapper 中 70% 的 span 和 90% 的 trace 都至少有一个应用指定的标注。</p>

<p>我们有 41 个 Java 应用和 68 个 C++ 应用添加了自定义的标注以便更好地理解 span 内的行为。值得注意的是 Java 开发者在每个 span 上加的标注比 C++ 开发者更多，这也许是因为 Java 的负载更接近最终用户；这类应用经常处理更广的请求，所以控制路径也相对更复杂。</p>

<h2>4 管理跟踪损耗</h2>

<p>跟踪系统的成本是由于生成追踪和收集数据造成的系统性能下降，以及用来存储和分析跟踪数据的资源量。尽管你可以说一个有价值的跟踪系统即便造成一点性能损耗也是值得的，但是我们相信如果基线损耗达到可以忽略的程度，那么一定会对跟踪系统的最初推广大有裨益。</p>

<p>本节我们将展示 Dapper 性能测量操作的消耗、跟踪收集的消耗、以及 Dapper 对生产环境负载的影响。同时还会介绍 Dapper 的适应性采样机制是如何帮助我们平衡低损耗的需求与代表性跟踪的需求。</p>

<h3>4.1 跟踪生成的损耗</h3>

<p>跟踪生成的损耗是 Dapper 性能影响中最重要的部分，因为收集和分析可以在紧急情况下关闭掉。Dapper 运行库生成跟踪的消耗最重要的原因是创建销毁 span 和标注、以及记录到本地磁盘以便后续的收集。非根 span 的创建和销毁平均需要 176 纳秒，而根 span 则需要 204 纳秒。这个差别是因为要对根 span 分配全局唯一 trace id 的时间。</p>

<p>如果一个 span 没有被采样的话，那么额外标注的成本则几乎可以忽略不计，只需 Dapper 运行时在ThreadLocal 中查找，平均花费 9 纳秒。而如果这个 span 被采样的话，对 span 进行字符串标注（见图4）则平均需要花费 40 纳秒。这些数据都是基于 2.2GHz x86 服务器测量得出的。</p>

<p>Dapper 运行时库最昂贵的操作就是写入本地磁盘了，不过这个损耗可以大大减少，因为每个磁盘都会合并对多个日志文件写入操作，并且相对于被跟踪的应用系统来说是异步执行的。尽管如此，日志写入对高吞吐量系统仍然可能有可见的性能影响，尤其是当所有请求都都被跟踪时。在 4.3 节我们对一次Web 搜索过程中生成跟踪的损耗进行了量化。</p>

<h3>4.2 跟踪收集的损耗</h3>

<p>读出本地的跟踪数据也会对正在监控的系统产生影响。表1 展示了在高于实际负载的测试情况下，Dapper 守护进程 CPU 使用率的最坏情况。</p>

<table>
<thead>
<tr>
<th style="text-align:right;"> Process Count (per host) </th>
<th style="text-align:right;"> Data Rate (per process) </th>
<th style="text-align:right;"> Daemon CPU Usage (single CPU core) </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">                       25 </td>
<td style="text-align:right;">                 10K/sec </td>
<td style="text-align:right;">                             0.125% </td>
</tr>
<tr>
<td style="text-align:right;">                       10 </td>
<td style="text-align:right;">                200K/sec </td>
<td style="text-align:right;">                             0.267% </td>
</tr>
<tr>
<td style="text-align:right;">                       50 </td>
<td style="text-align:right;">                  2K/sec </td>
<td style="text-align:right;">                             0.130% </td>
</tr>
</tbody>
</table>


<p><em>(表-1. Dapper 守护进程在负载测试中 CPU 资源使用率)</em></p>

<p>Dapper 守护进程在跟踪收集过程中，对生产环境单核 CPU 的占用率从未超过 0.3%，并且内存占用也很小。同时我们把 Dapper 守护进程在内核 scheduler 中的优先级限制到尽可能最低，以防在高负载机器上出现 CPU 竞争。</p>

<p>Dapper 对网络资源的消耗也轻量，我们仓库中每个 span 平均只有 426 byte。Dapper 跟踪数据在Google 生产环境中占用的网络流量小于 0.01%。</p>

<h3>4.3 对生产环境负载的影响</h3>

<p>高吞吐量的在线服务处理每个请求都会用到大量的机器，这种在线服务最有需求进行高效的跟踪；他们会生成大量的跟踪数据，同时也对性能影响是最敏感的。在表2 中我们用 web 搜索集群作为例子，通过调整采样率，来测量 Dapper 对平均延迟和吞吐量的性能影响。</p>

<table>
<thead>
<tr>
<th style="text-align:right;"> Sampling frequency </th>
<th style="text-align:right;"> Avg. Latency (% change) </th>
<th style="text-align:right;"> Avg. Throughput (% change) </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">                1/1 </td>
<td style="text-align:right;">                   16.3% </td>
<td style="text-align:right;">                     -1.48% </td>
</tr>
<tr>
<td style="text-align:right;">                &frac12; </td>
<td style="text-align:right;">                   9.40% </td>
<td style="text-align:right;">                     -0.73% </td>
</tr>
<tr>
<td style="text-align:right;">                &frac14; </td>
<td style="text-align:right;">                   6.38% </td>
<td style="text-align:right;">                     -0.30% </td>
</tr>
<tr>
<td style="text-align:right;">                1/8 </td>
<td style="text-align:right;">                   4.12% </td>
<td style="text-align:right;">                     -0.23% </td>
</tr>
<tr>
<td style="text-align:right;">               1/16 </td>
<td style="text-align:right;">                   2.12% </td>
<td style="text-align:right;">                     -0.08% </td>
</tr>
<tr>
<td style="text-align:right;">             1/1024 </td>
<td style="text-align:right;">                  -0.20% </td>
<td style="text-align:right;">                     -0.06% </td>
</tr>
</tbody>
</table>


<p><em>(表-2. Dapper 采样频率对 Web 搜索集群延迟及吞吐量的影响。延迟及吞吐量的实验误差分别为 2.5% 和 0.15%)</em></p>

<p>可以看到，虽然对吞吐量的影响不是很明显，但为了避免明显的延迟，跟踪采样还是非常有必要的。然而，当采样率小于 1/16 时的延迟和吞吐量损失是在实验误差范围内的。实践中，我们发现对于高容量服务来说，即便把采样率设为 1/1024 这样低，仍然能够得到足够多的跟踪数据。保持 Dapper 的性能损耗基线极其低是很重要的，因为这就能为应用程度提供一个宽松的环境来使用完整的标注 API，而无需担心性能损失。使用低采样率还有一个额外的好处，可以让主机磁盘中的数据在被垃圾回收之前能持久化更长的时间，这就让收集组件有了更多的灵活性。</p>

<h3>4.4 适应性采样</h3>

<p>Dapper 对于任何给定进程的损耗是与单位时间内进程跟踪的数目成正比的。Dapper 的第一个生产版本在 Google 的几乎所有进程上使用同一个采样率，每 1024 个候选中平均采样一个。这个简单的方案对高吞吐量在线服务是有效的，因为大多数我们感兴趣的事件仍然会经常出现并被捕捉到。</p>

<p>然而，低流量的服务在这种低采样率下就可能会错失重要的事件，而更高采样率带来的性能损耗是可接受的。针对这种系统的解决方案是覆盖默认采样率，而这就需要手工干预，我们不想在 Dapper 中出现这种手工干预。</p>

<p>我们正在部署一种适应性的采样机制，不使用统一的采样率，而使用单位时间内的期望采样率。这样，低流量负载会自动提高采样率，而高流量负载则会自动降低采样率，从而掌控损耗。实际采样率会和跟踪数据一起记录下来；这有利于在基于 Dapper 数据的分析工具中精准使用采样率。</p>

<h3>4.5 应对激进采样</h3>

<p>Dapper 新用户往往觉得低采样率（高流量服务中通常会低于 0.01%）会干扰他们的分析。我们在Google 中应用的经验让我们相信，对于高吞吐量服务来说，激进采样并不会妨碍最重要的那些分析。如果一个重要的执行模式在这种系统中出现过一次，那么就会出现上千次。每秒请求几十次而不是上万次的那些低流量服务则可以承受跟踪每一个请求；这驱动着我们往适应性采样方向前进。</p>

<h3>4.6 收集过程中的额外采样</h3>

<p>上述采样机制用来尽量减少与 Dapper 运行时库协作的应用程序中的性能损耗。Dapper 团队还需要控制写入中央仓库的数据量，为此我们引入了第二轮采样。</p>

<p>目前我们生产集群每天产生超过 1 TB 的采样跟踪数据。Dapper 用户希望跟踪数据从生产进程中记录下来后最少保留两周时间。逐渐增长的跟踪数据带来了好处，同时 Dapper 仓库的机器和磁盘存储成本也在增加，我们需要作出权衡。对请求的高采样率还会使得 Dapper 收集器接近 Dapper Bigtable 仓库的写入吞吐量极限。</p>

<p>为了维持物资资源的需求和 Bigtable 的累积写入吞吐量之间的灵活性，我们在收集系统自身上增加了额外的采样。一个特定 trace 中的所有 span 都共享同一个trace id，即便这些span可能横跨数千个不同的主机。<strong>对于在收集系统中的每个 span，我们将其 trace id 哈希成一个标量 z （0&lt;=z&lt;=1）。如果 z 小于我们的收集采样系数，我们就保留这个 span 并将它写入 Bigtable；否则就丢弃</strong>。在采样决策中通过依靠 trace id，我们要么采样整个 trace，要么抛弃整个 trace，而不会对 trace 中的某些span进行处理。我们发现这种额外配置参数让我们对收集管道的管理变得简单得多，因为可以很容易地调整全局写入率，仅仅修改配置文件中的一个参数即可。</p>

<p>如果整个跟踪和收集系统都是用同一个采样参数则会更简单，但是那样就无法灵活地快速调整所有部署环境中的运行时采样配置。我们选择的运行时采样率产生的数据会稍微高于我们能写入仓库的数据，而我们可以通过调整收集系统中的二级采样参数对写入速度进行限流。因为我们可以通过对二级采样配置一下就能增加或减少全局覆盖率和写入速率，所以 Dapper 管道的维护工作变得更简单了。</p>

<h2>5 通用 Dapper 工具</h2>

<p>几年前当 Dapper 还是一个原型时，在开发者的耐心支持下才能把 Dapper 用起来。从那时起，我们逐渐建立了收集组件、编程接口、以及基于 web 的用户交互界面，帮助 Dapper 用户独立地解决自己的问题。本节将总结哪些方法有用，哪些没用，并提供这些通用的分析工具的基本使用信息。</p>

<h3>5.1 Dapper Depot API</h3>

<p>Dapper Deport API 又称 DAPI，通过它可以直接访问 Dapper 区域仓库中的分布式跟踪数据。DAPI 和 Dapper 跟踪仓库是串行设计的，DAPI 意在为 Dapper 仓库中的原始数据提供一个干净而直观的接口。我们的用例推荐如下三种方式来访问跟踪数据：</p>

<p><strong>通过trace id访问（Access by trace id）：</strong>DAPI 可以根据全局唯一的 trace id 来加载任何一次跟踪。</p>

<p><strong>批量访问（Bulk access）：</strong>DAPI 可通过 MapReduce 来并行访问数亿条 Dapper 跟踪数据。用户重写一个虚拟函数，它的唯一参数接受一个 Dapper 跟踪信息，然后框架将会对用户指定时间窗口内的每一条跟踪信息调用一次该函数。</p>

<p><strong>索引访问（Indexed access）：</strong>Dapper 仓库支持一个唯一索引，可用于匹配我们通用的访问模式。该索引将通用请求的跟踪特性映射到特定的 Dapper 跟踪。因为 trace id 是伪随机创建的，所以这是快速访问某个特定服务或特定主机追踪信息的最佳方式。</p>

<p>所有这三种访问方式都将用户引导到特定的 Dapper 追踪记录。正如 2.1 节所述，Dapper 的跟踪信息是由 trace span 组成的树，所以 <code>Trace</code> 数据结构就是一个由不同 <code>Span</code> 结构组成的遍历树。Span 通常对应 RPC 调用，在这种情况下，RPC 的耗时信息是有的。通过 span 结构还可访问基于时间戳的引用标注信息。</p>

<p>选择合适的用户索引是DAPI 设计中最具挑战性的部分。索引要求的压缩存储只比实际数据本身小 26%，所以成本是巨大的。最初我们部署了两个索引：<strong>一个是主机索引，另一个是服务名索引</strong>。然而我们发现相对于存储成本来说，用户对主机索引的兴趣尚不足够。当用户对某台机器的跟踪感兴趣的时候，他们也会对特定的服务感兴趣，所以我们最终将这两个索引合并成一个组合索引，允许按服务名、主机、时间戳高效地进行查找。</p>

<h4>5.1.1 DAPI 在 Google 内部的使用</h4>

<p>Dapper 在 Google 的使用有三类：使用 DAPI 的持久在线 web 应用，可在命令行启动的维护良好的基于 DAPI 的工具，以及编写、运行、然后即被遗忘的一次性分析工具。我们知道的有3 个基于DAPI的持久性应用、8个基于DAPI的分析工具、约15~20个一次性分析工具。在这之后就很难统计这些工具了，因为开发者可以构建、运行、然后丢弃，而不需要让 Dapper 团队知道。</p>

<h3>5.2 Dapper 用户接口</h3>

<p>绝大多数情况下，人们通过基于 web 的用户交互接口来使用 Dapper。篇幅所限我们不能展示每一个特性，不过图6 列出了一个典型的用户工作流。</p>

<p><img src="/images/post/2019/dapper/dapper-6_workflow.png" alt="dapper-6_workflow" /></p>

<p><em>(图-6. 通用 Dapper 用户接口中的一个典型用户工作流)</em></p>

<ol>
<li>用户输入他们关心的服务名以及时间窗口，再加上任何需要来区分跟踪模式的信息（例如span名称）。同时指定与他们的搜索最相关的成本度量（例如服务响应时间）。</li>
<li>然后就会出现一个性能概要的大表格，总结了与给定服务相关的所有分布式执行模式。用户可以根据他们的需要对执行模式进行排序，并选择其中一个查看更多细节。</li>
<li>一旦选中一个分布式执行模式，用户则会看到关于这个执行模式的图形化描述。被选中的服务在图表中央被高亮显示。</li>
<li>在创建与第 1 步选中的成本度量相关的统计信息后，Dapper 用户界面会展示一个简单的频率直方图。所以在这个例子中，我们能看到选中的执行模式相关的响应时间大概是对数正态分布的。用户还会看到一个特定跟踪样例的列表，这些样例分布在直方图的不同区间。本例中，用户点击第二个跟踪样例，在 Dapper 用户界面打开跟踪详细视图。</li>
<li>绝大多数 Dapper 用户最终会检查特定的跟踪，希望收集系统行为根本原因的信息。我们没有足够的空间去做跟踪视图的审查，但我们有个全局时间线，并能交互地展开或折叠子树，这是我们的特点。分布式跟踪树的连续层用内嵌的不同颜色的矩形表示。每个 RPC span 分为服务进程处理时间（绿色）和网络消耗时间（蓝色）。用户标注没有显示在这个截图中，不过可以以 span 为基础将他们选择性地包含在全局时间线上。</li>
</ol>


<p>对于想查询实时数据的用户，Dapper 用户界面支持直接与每台生产环境服务器上的守护进程通信。在这个模式下，不能像上图那样查看系统级别的图表，不过仍然很容易地基于耗时和网络特性选择一个跟踪。在这个模式下，可在几秒内实时地查到数据。</p>

<p>根据我们的日志，每个工作日大概有 200 个 Google 工程师使用 Dapper UI；每周大约有 750 到 1000个独立用户访问。忽略掉发布新功能的因素，这个数据每个月都是一致的。用户通常会发送出特定跟踪的链接，这会不可避免地在跟踪查询中产生很多一次性的、短期的流量。</p>

<h2>6 经验</h2>

<p>Dapper 在 Google中被广泛使用，通过 Dapper 用户界面直接访问，或者通过编程 API 以及基于这些API 构建的程序访问。本节我们不打算罗列出每一种已知的 Dapper 的使用方式，而会尝试讲解 Dapper 使用的"基本向量"，阐述何种应用是最成功的。</p>

<h3>6.1 开发过程中使用 Dapper</h3>

<p>Google AdWords 系统建立在关键词定位准则和相关文字广告的大型数据库之上。当新的关键词被插入或修改时，必须对他们进行校验，以遵循服务策略条款（例如检查不恰当的语言）；这个过程使用自动审查系统来做的话会更有效率。</p>

<p>当从头开始重新设计一个广告审查服务时，团队从第一个系统原型开始，直到最终的系统维护，都使用了 Dapper。他们的服务通过 Dapper 有了以下方面的提高：</p>

<p><strong>性能（Performance）：</strong>开发人员跟踪请求延迟目标的进度，精确找到可优化的机会。Dapper 还被用来找出关键路径中的不必要请求序列（这种不必要请求通常源于不是开发者自己开发的子系统），然后促使相关团队修复这些问题。</p>

<p><strong>正确性（Correctness）：</strong>广告审查服务是围绕大型数据库系统的。系统同时具有只读副本服务器（廉价访问），以及可读写的主服务器（昂贵访问）。他们通过 Dapper 找到了好些不必要地访问主服务器而不是访问副本服务器的查询。Dapper 现在可用于解释主服务器被直接访问的原因，确保重要系统的不变式。</p>

<p><strong>理解性（Understanding）：</strong>广告审查查询跨越多种类型的系统，包括 Bigtable（即前文提到的数据库）、多维索引服务、以及许多其他 C++ 和 Java 后端服务。Dapper 跟踪用来评估总查询成本，促进对业务重新设计，使得系统依赖的负载最小。</p>

<p><strong>测试（Testing）：</strong>新代码的发布会经过一个 Dapper 跟踪的 QA 过程，验证正确的系统行为和性能。这个过程中发现了很多问题，包括广告审查代码自身的问题，及其依赖包的问题。</p>

<p>广告审查团队广泛使用了 Dapper 标注 API。Guice<sup>[13]</sup> 开源的 AOP 框架用来在重要的软件组件上标注 <code>@Traced</code>。跟踪信息进一步标注的信息有重要子程序的输入输出大小、状态消息、以及其他调试信息；否则这些信息会被发到日志文件中。</p>

<p>Dapper 在广告审查团队的应用有一些不足的地方。例如，他们想在交互时间内搜索所有的跟踪标注，然而必须运行自定义的 MapReduce 或者手工检查每个跟踪。另外，Google 内还有其他的系统对通用目的的调试日志进行收集并进行集中化，把这些系统中的海量数据和 Dapper 仓库进行整合是有价值的。</p>

<p>即便如此，总的来说广告审查团队估计通过 Dapper 跟踪平台的数据分析，他们的延迟数据已经优化了两个数量级。</p>

<h4>6.1.1 与异常监控的集成</h4>

<p>Google 维护了一个从运行进程中不断收集并集中异常报告的服务。如果这些异常发生在被采样的Dapper 跟踪中，则异常报告中会包含相关的 trace id 和 span id。然后异常监控服务前端就会在特定异常报告里提供一个链接，指向相应分布式跟踪。广告审查团队利用这个特性，来了解异常监控服务发现的那些 bug 的更大范围的上下文。Dapper 平台通过导出基于简单唯一 ID 构建的接口，相对容易地集成到其他事件监控系统中。</p>

<h3>6.2 解决长尾延迟</h3>

<p>由于移动部件的数量、代码库及部署的规模，调试一个像全文搜索（universal search）那样的服务是非常有挑战性的。这里我们描述在减轻全文搜索延迟分布的长尾效应上做的努力。Dapper 能够验证端到端延迟的假设，更具体地说，它能够<strong>验证全文搜索请求的关键路径</strong>。当系统不仅涉及多个子系统，还涉及多个开发团队时，即便我们最好最有经验的工程师也经常猜错端到端性能差的根本原因。在这种情况下，Dapper 可以提供必需的事实，可以回答许多重要的性能问题。</p>

<p>一个工程师在调试长尾延迟的过程中建立了一个小型库，可以根据 DAPI <code>Trace</code>对象推断出层次性的关键路径。这些关键路径结构可用来诊断问题、为全文搜索可预期的性能改进调整优先级。Dapper 的这项工作引出了下列发现：</p>

<ul>
<li>关键路径上短暂的网络性能退化不会影响系统吞吐量，但能对延迟异常值产生巨大影响。在图7 中，大多数全文搜索的慢跟踪都在关键路径上有网络退化。
<img src="/images/post/2019/dapper/dapper-7_network-lag.png" alt="dapper-7_network-lag" />
<em>(图-7. 关键路径上遇到非正常网络延迟的全文搜索跟踪，与端到端请求延迟的关系)</em></li>
<li>许多有问题的昂贵查询模式都源自服务间不经意的交互。一旦发现，他们往往很容易纠正；但是在没有 Dapper 时如何发现他们是很困难的。</li>
<li>通用查询是从 Dapper 之外的安全日志仓库中获取，并且使用 Dapper 的唯一 trace id，与Dapper 仓库做关联。这种映射随后被用于构建全文搜索每个独立子系统中的慢查询列表。</li>
</ul>


<h3>6.3 推断服务依赖</h3>

<p>在任意指定时刻，Google 的典型计算集群是成千上万个逻辑"任务"组成；一系列进程执行通用函数。Google 维护着许多这种集群，当然我们发现一个计算集群中的任务往往依赖其他集群中的任务。由于任务间的依赖是动态改变的，所以不可能仅仅从配置信息中推断出所有的服务间依赖。尽管如此，公司内部的许多进程要求知道准确的服务依赖信息，以便找出瓶颈，计划服务的迁移。Google 的"服务依赖"项目通过使用跟踪标注以及 DAPI MapReduce 接口，自动探测服务间的依赖。</p>

<p>使用 Dapper 核心性能检测以及 Dapper 的跟踪标注，服务依赖项目能够推断出任务之间的依赖关系，还能推断出这些任务所依赖的程序组件。例如，所有 Bigtable 的操作被标记上受影响的表名。通过 Dapper 平台，服务依赖团队就可以自动推断出多种服务粒度的依赖关系。</p>

<h3>6.4 不同服务的网络使用率</h3>

<p>Google 在网络结构上投入了大量的人力物力。毫无疑问，网络运维人员要关注单个硬件的监控信息、自定义工具和 dashboard，来查看全局网络使用情况的鸟瞰图。网络运维人员可以一览整个网络的健康状况，但是当出现问题时，他们却缺少工具找到网络负载问题在应用级别的罪魁祸首。</p>

<p>虽然 Dapper 并不是设计用来做链路级的监控，但我们发现它非常适合集群之间网络活动应用级别分析的任务。Google 利用 Dapper 平台得以建立不断更新的终端，来显示集群间网络流量中最活跃的那些应用级别端点。此外，通过 Dapper 我们可以找出引起昂贵网络请求的跟踪，而不是面对孤立的机器。在 Dapper API 之上建立 dashboard 花费的时间没超过两周。</p>

<h3>6.5 分层及共享的存储系统</h3>

<p>Google 的许多存储系统都由多个独立的复杂层次的分布式基础设施组成。例如，Google App Engine<sup>[5]</sup> 就是建立在一个可扩展实体存储系统之上。这个实体存储系统基于底层的 BigTable 暴露出一些 RDBMS 功能。Bigtable 则同时使用 Chubby<sup>[7]</sup>（一个分布式锁系统）及 GFS。此外，像 BigTable这类系统会作为共享服务来管理，以简化部署并更好地利用计算资源。</p>

<p>在这种分层系统中，并不总是很容易发现终端用户的资源消费模式。例如，给定 BigTable 单元对 GFS 的大量请求可能来自一个用户或者许多用户，而在 GFS 层面这两种不同的使用模式的区别是模糊的。而且，如果缺乏像 Dapper 这种工具的话，对这种共享服务的竞争同样是难以调试的。</p>

<p>5.2节展示的 Dapper 用户界面可以分组聚合共享服务横跨多个客户端的跟踪性能信息。这就使得共享服务的负责人可以容易地根据多个指标对其用户进行排名（例如根据inbound网络负载、outbound网络负载、或者服务请求的总时间）。</p>

<h3>6.6 用 Dapper 来救火</h3>

<p>Dapper 对于某些救火任务是有用的。这里的"救火"指的是对处于危险中的分布式系统进行的操作。典型情况下，Dapper 用户在进行救火时需要访问新鲜数据，并且没有时间写新的 DAPI 代码，也没时间等待周期性的报告运行。</p>

<p>对于那些正在经历高延迟的服务，或者更糟的在正常负载下都会超时的服务，Dapper 用户界面通常能把这些延迟的瓶颈隔离出来。通过与 Dapper 守护进程直接通信，可以容易地收集特定高延迟跟踪的新鲜数据。在灾难性故障时，通常没必要分析统计数据来确定根本原因，而查看示例跟踪就足够了。</p>

<p>然而，6.5 节描述的那种共享存储服务则要求当用户活动突然激增时能快速聚合信息。对于事后检验，共享服务仍然可以利用 Dapper 的聚合数据，但是除非可以在十分钟之内完成对 Dapper 数据的批量分析，否则 Dapper 对共享存储服务的救火就不会那么有用了。</p>

<h2>7 其他经验教训</h2>

<p>虽然我们在 Dapper 上的经验已经基本满足我们的预期，但是也有一些积极的方面是我们没有充分预料到的。我们对非计划中的用例数目感到高兴。除了在第6节描述的一些经验外，还包括资源核算系统，用来检查敏感服务是否遵从指定的通讯模式的工具，RPC 压缩策略的分析工具，等等。这些非计划中的用例一定程度上归功于我们通过一个简单的编程接口开放了跟踪数据存储，这就允许我们利用上这个大得多的社区的创造力。Dapper 对旧系统的支持也比预期更简单，只需要基于新版本的库重新编译即可，这个库提供通用线程、控制流和 RPC 框架。</p>

<p>Dapper 在 Google 内部的广泛使用还为我们提供了关于其局限性的宝贵反馈。下面我们将介绍一些我们已知的最重要的一些不足之处。</p>

<p><strong>合并的影响（Coalescing effects）：</strong>Dapper 模型隐式地设想不同子系统一次只会处理一个跟踪请求。在某些情况下，在对一组请求执行操作之前缓冲一些请求会更有效率（例如对磁盘写入进行合并）。在这些情况下，一个跟踪请求可以看做是一个大型工作单元(a traced request can be blamed for a deceptively large unit of work)。此外，如果多个跟踪请求被批量执行，那么只会有一个请求被 span使用，这是因为我们我们对每个跟踪只会有一个唯一 trace id（if multiple traced requests are batched together, only one of them will appear responsible for the span due to our reliance on a single unique trace id for each trace）。我们正在考虑解决方案以识别这种情况，并记录最少的信息来区别这些请求。</p>

<p><strong>跟踪批处理系统（Tracing batch workloads）：</strong>Dapper 的设计是针对在线服务系统，最初的目标是了解 Google 的用户请求引起的系统行为。然而，离线的数据密集型系统也可以从对性能的洞悉中获益，例如适合 MapReduce 模型的系统。在这种情况下，我们需要把 trace id 关联到一些其他的有意义的工作单元，例如输入数据的 key（或key范围），或是一个 MapReduce shard。</p>

<p><strong>寻找根本原因（Finding a root cause）：</strong>Dapper 可以有效地确定系统中的哪个部分正在经历速度变慢，但并不总是足够找出问题的根本原因。举个例子，一个请求变慢可能并不是因为他自己的行为，而是因为其他请求还排在他前面。程序可以利用应用级别的标注把队列大小和过载情况转播到跟踪系统。同时，如果这种情况很常见，那么在ProfileMe<sup>[11]</sup> 中提出的成对采样技术就很有用了。它对两个时间重叠的请求进行采样、并观察它们在系统中的相对延迟。</p>

<p><strong>记录内核级别的信息（Logging kernel-level information）：</strong>内核可见事件的详细信息有时对确定问题根本原因很有用。我们有一些工具能够跟踪或者描述内核的执行，但是要想将这些信息绑定到用户级别的跟踪上下文上，用通用或是不那么突兀的方式是很难的。我们正在研究一种可能的妥协方案，对用户层面上的一些内核级别活动参数做快照，将其关联到一个活动 span 上。</p>

<h2>8 相关工作</h2>

<p>在分布式系统跟踪领域，有一套完整的体系，一些系统主要关注定位到故障位置，另一些系统关注性能优化。Dapper 曾被用于故障发现，但它在发现性能问题、提升对大型复杂系统行为的理解方面更有用。</p>

<p>Dapper 与黑盒监控系统有关，就像 Project5<sup>[1]</sup>、WAP5<sup>[15] </sup>和 Sherlock<sup>[2]</sup>，黑盒监控系统不依赖于运行时库的性能测量，能够实现更高度的应用级透明。黑盒的缺点是有些不精确，并在统计推断因果路径过程中可能损耗更大。</p>

<p>对分布式系统的监控来说，显式的基于标注的中间件或应用本身的性能测量或许是更受欢迎的方式。Pip<sup>[14] </sup>和 Webmon<sup>[16] </sup>更依赖于应用级的标注，而 X-Trace<sup>[12]</sup>、Pinpoint<sup>[9] </sup>和 Magpie<sup>[3]</sup> 则侧重对库和中间件的修改。Dapper 更接近后者。Dapper 与 Pinpoint、X-Trace 以及最新版本的 Magpie 类似，使用全局 ID 将分布式系统不同部分的相关事件关联起来。同样和这些系统类似，Dapper 把性能测量隐藏在通用软件模块中，尝试避免标注应用程序。Magpie 放弃使用全局 ID，就不用处理正确传播全局 ID 带来的挑战，而是为每个应用写入<code>事件模式（event schema）</code>并显式地描述事件之间的关系。我们不清楚 schema 在实践中实现透明性到底有多有效。X-Trace 的核心标注需求比 Dapper 更有雄心，不仅在节点边界收集跟踪，还在节点内部不同软件层级间收集跟踪。而我们对于性能测量低损耗的要求迫使我们不能采用这种模式，而是朝着把一个请求连接起来完整跟踪所能做到的最小代价而努力。Dapper 跟踪仍然能通过可选的应用标注来扩展。</p>

<h2>9 总结</h2>

<p>本文介绍了 Google 生产环境下的分布式系统跟踪平台 Dapper，并汇报了我们开发和使用 Dapper 的经验。Dapper 部署在 Google 的几乎所有系统上，使得大型系统得以被跟踪而无需修改应用程序，同时没有明显的性能影响。通过 Dapper 主跟踪用户界面的受欢迎程度可以看出 Dapper 对开发团队和运维团队的实用性，本文通过一些使用场景的例子也阐明了 Dapper 的实用性，甚至有些使用场景 Dapper 的设计者都未曾预料到。</p>

<p>据我们所知，本文是第一篇汇报一个大型的生产环境下的分布式系统跟踪框架的论文。实际上我们主要的贡献源于这样一个事实：我们汇报回顾的系统已经被使用超过两年了。我们发现，决定结合最小化应用透明的跟踪功能以及对程序员提供简单的 API 来增强跟踪是非常值得的。</p>

<p>我们相信，Dapper 比之前基于标注的分布式跟踪系统达到了更高的应用级透明性，只需要很少的人工干预。虽然这也归功于我们计算部署的一定程度上的同质性，但仍然是一个重大的挑战。最重要的是，我们的设计提出了一些实现应用级透明的充分条件，我们希望能够对更异质的环境下的解决方案有所帮助。</p>

<p>最后，通过把 Dapper 跟踪仓库开放给内部开发者，促使了更多分析工具的产生，而仅仅由 Dapper 团队封闭地独自开发肯定产生不了这么多工具，这大大提高了设计和实现的成就。</p>

<h2>Acknowledgments</h2>

<p>We thank Mahesh Palekar, Cliff Biffle, Thomas Kotzmann, Kevin Gibbs, Yonatan Zunger, Michael Kleber, and Toby Smith for their experimental data and feedback about Dapper experiences. We also thank Silvius Rus for his assistance with load testing. Most importantly, though, we thank the outstanding team of engineers who have continued to develop and improve Dapper over the years; in order of appearance, Sharon Perl, Dick Sites, Rob von Behren, Tony DeWitt, Don Pazel, Ofer Zajicek, Anthony Zana, Hyang-Ah Kim, Joshua MacDonald, Dan Sturman, Glenn Willen, Alex Kehlenbeck, Brian McBarron, Michael Kleber, Chris Povirk, Bradley White, Toby Smith, Todd Derr, Michael De Rosa, and Athicha Muthitacharoen. They have all done a tremendous amount of work to make Dapper a day-to-day reality at Google.</p>

<h2>References</h2>

<p>[1]  M. K. Aguilera, J. C. Mogul, J. L. Wiener, P. Reynolds, and A. Muthitacharoen. Performance Debugging for Dis- tributed Systems of Black Boxes. In <em>Proceedings of the 19th ACM Symposium on Operating Systems Principles</em>, December 2003.</p>

<p>[2]  P. Bahl, R. Chandra, A. Greenberg, S. Kandula, D. A. Maltz, and M. Zhang. Towards Highly Reliable Enter- prise Network Services Via Inference of Multi-level De- pendencies. In <em>Proceedings of SIGCOMM</em>, 2007.</p>

<p>[3]  P.Barham,R.Isaacs,R.Mortier,andD.Narayanan.Mag- pie: online modelling and performance-aware systems. In <em>Proceedings of USENIX HotOS IX</em>, 2003.</p>

<p>[4]  L. A. Barroso, J. Dean, and U. Ho ̈lzle. Web Search for a Planet: The Google Cluster Architecture. <em>IEEE Micro</em>, 23(2):22–28, March/April 2003.</p>

<p>[5]  T. O. G. Blog. Developers, start your engines. <a href="http://googleblog.blogspot.com/2008/04/developers-">http://googleblog.blogspot.com/2008/04/developers-</a> start-your-engines.html, 2007.</p>

<p>[6]  T. O. G. Blog. Universal search: The best answer is still the best answer. <a href="http://googleblog.blogspot.com/2007/05/universal-">http://googleblog.blogspot.com/2007/05/universal-</a> search-best-answer-is-still.html, 2007.</p>

<p>[7]  M. Burrows. The Chubby lock service for loosely- coupled distributed systems. In <em>Proceedings of the 7th USENIX Symposium on Operating Systems Design and Implementation</em>, pages 335 – 350, 2006.</p>

<p>[8]  F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A. Wal- lach, M. Burrows, T. Chandra, A. Fikes, and R. E. Gru- ber. Bigtable: A Distributed Storage System for Struc- tured Data. In <em>Proceedings of the 7th USENIX Sympo- sium on Operating Systems Design and Implementation (OSDI’06)</em>, November 2006.</p>

<p>[9]  M. Y. Chen, E. Kiciman, E. Fratkin, A. fox, and E. Brewer. Pinpoint: Problem Determination in Large, Dynamic Internet Services. In <em>Proceedings of ACM In- ternational Conference on Dependable Systems and Net- works</em>, 2002.</p>

<p>[10]  J. Dean and S. Ghemawat. MapReduce: Simplified Data Processing on Large Clusters. In <em>Proceedings of the 6th USENIX Symposium on Operating Systems Design and Implementation (OSDI’04)</em>, pages 137 – 150, December 2004.</p>

<p>[11]  J. Dean, J. E. Hicks, C. A. Waldspurger, W. E. Weihl, and G. Chrysos. ProfileMe: Hardware Support for Instruction-Level Profiling on Out-of-Order Processors. In <em>Proceedings of the IEEE/ACM International Sympo- sium on Microarchitecture</em>, 1997.</p>

<p>[12]  R. Fonseca, G. Porter, R. H. Katz, S. Shenker, and I. Sto- ica. X-Trace: A Pervasive Network Tracing Framework. In <em>Proceedings of USENIX NSDI</em>, 2007.</p>

<p>[13]  B. Lee and K. Bourrillion. The Guice Project Home Page. <a href="http://code.google.com/p/google-guice/,">http://code.google.com/p/google-guice/,</a> 2007.</p>

<p>[14]  P. Reynolds, C. Killian, J. L. Wiener, J. C. Mogul, M. A. Shah, and A. Vahdat. Pip: Detecting the Unexpected in Distributed Systems. In <em>Proceedings of USENIX NSDI</em>, 2006.</p>

<p>[15]  P. Reynolds, J. L. Wiener, J. C. Mogul, M. K. Aguilera, and A. Vahdat. WAP5: Black Box Performance Debug- ging for Wide-Area Systems. In <em>Proceedings of the 15th International World Wide Web Conference</em>, 2006.</p>

<p>[16]  P. K. G. T. Gschwind, K. Eshghi and K. Wurster. Web- Mon: A Performance Profiler for Web Transactions. In <em>E-Commerce Workshop</em>, 2002.</p>
]]></content>
  </entry>
  
</feed>
